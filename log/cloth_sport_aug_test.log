nohup: ignoring input
using gpu:1 to train the model
using gpu:1 to train the model
cuda:1
Namespace(A_split=False, JK='sum', a_fold=100, aggregate=False, batch_size=1024, beta=1.5, conv_layers=3, cuda=True, decay_epoch=5, device=device(type='cuda', index=1), device_id='1', domains='cloth_sport', dropout=0.2, epoch=70, feature_dim=126, hidden_dim=126, keep_prob=0.6, lambda_constra=0.15, lambda_critic=0.35, lambda_ease=50, leakey=0.01, load=False, log='logs.txt', log_epoch=5, lr=0.0005, lr_decay=0.95, lr_transfer=0.0005, mask_rate=0.1, min_epoch=50, mode='train', model_file=None, model_name='cs', num_latent_factors=3, num_negative=10, optim='adam', patience=50, proj_layers=1, projection=1, residual=1, save=True, save_dir='./saved_models', seed=32, sim_threshold=0.9, tau=0.4, test_sample_number=999, transfer_epoch=60, user_batch_size=256, weight_decay=0.0002)
number_user 41829
number_item 17943
/home/hourun/invariantCDR_v2/invariantCDR/utils/GraphMaker.py:47: RuntimeWarning: divide by zero encountered in power
  r_inv = np.power(rowsum, -1).flatten()
real graph loaded!
augmented graph loaded!
number_user 27328
number_item 12655
real graph loaded!
augmented graph loaded!
graph loaded!
Loading data from cloth_sport with batch size 1024...
unseen test: 0
test length: 3156
unseen test: 0
test length: 3085
unseen test: 0
test length: 3589
unseen test: 0
test length: 3546
source_user_num 41829
target_user_num 27328
source_item_num 17943
target_item_num 12655
shared users id: 7857
test users 990, 982
unseen test: 0
dev length: 1000
unseen test: 0
dev length: 1000
source train data : 187880, target train data: 163291, source test data : 3085, target test data : 3546, source dev data : 1000, target dev data : 1000
2024-07-10 10:18:42.671084: step 343/24010 (epoch 1/70), loss = 3.045805 (44.313 sec/epoch), lr: 0.000500
2024-07-10 10:19:25.724526: step 686/24010 (epoch 2/70), loss = 2.367730 (43.053 sec/epoch), lr: 0.000500
2024-07-10 10:20:09.058820: step 1029/24010 (epoch 3/70), loss = 2.124269 (43.334 sec/epoch), lr: 0.000500
2024-07-10 10:20:52.455554: step 1372/24010 (epoch 4/70), loss = 1.993587 (43.397 sec/epoch), lr: 0.000500
2024-07-10 10:21:35.598875: step 1715/24010 (epoch 5/70), loss = 1.888641 (43.143 sec/epoch), lr: 0.000500
Evaluating on dev set...
....................
source: 	 mrr: 0.040439	 ndcg_5: 0.0320	 ndcg_10: 0.0423	 hit@1:0.016000	 hit@5:0.0490	 hit@10: 0.0820
target: 	 mrr: 0.085450	 ndcg_5: 0.0750	 ndcg_10: 0.0929	 hit@1:0.037000	 hit@5:0.1110	 hit@10: 0.1670
new best model saved.

2024-07-10 10:22:19.067178: step 2058/24010 (epoch 6/70), loss = 1.772656 (43.058 sec/epoch), lr: 0.000500
2024-07-10 10:23:02.831719: step 2401/24010 (epoch 7/70), loss = 1.668767 (43.764 sec/epoch), lr: 0.000500
2024-07-10 10:23:45.856779: step 2744/24010 (epoch 8/70), loss = 1.598558 (43.025 sec/epoch), lr: 0.000500
2024-07-10 10:24:29.239616: step 3087/24010 (epoch 9/70), loss = 1.555749 (43.383 sec/epoch), lr: 0.000500
2024-07-10 10:25:12.634317: step 3430/24010 (epoch 10/70), loss = 1.516509 (43.395 sec/epoch), lr: 0.000500
Evaluating on dev set...
....................
source: 	 mrr: 0.103710	 ndcg_5: 0.0904	 ndcg_10: 0.1157	 hit@1:0.046000	 hit@5:0.1350	 hit@10: 0.2130
target: 	 mrr: 0.033269	 ndcg_5: 0.0247	 ndcg_10: 0.0322	 hit@1:0.012000	 hit@5:0.0370	 hit@10: 0.0610
new best model saved.

2024-07-10 10:25:56.319375: step 3773/24010 (epoch 11/70), loss = 1.484525 (43.296 sec/epoch), lr: 0.000500
2024-07-10 10:26:39.350598: step 4116/24010 (epoch 12/70), loss = 1.456450 (43.031 sec/epoch), lr: 0.000500
2024-07-10 10:27:22.798353: step 4459/24010 (epoch 13/70), loss = 1.428136 (43.448 sec/epoch), lr: 0.000500
2024-07-10 10:28:05.924102: step 4802/24010 (epoch 14/70), loss = 1.403705 (43.126 sec/epoch), lr: 0.000500
2024-07-10 10:28:49.148365: step 5145/24010 (epoch 15/70), loss = 1.389476 (43.224 sec/epoch), lr: 0.000500
Evaluating on dev set...
....................
source: 	 mrr: 0.129474	 ndcg_5: 0.1140	 ndcg_10: 0.1463	 hit@1:0.059000	 hit@5:0.1660	 hit@10: 0.2670
target: 	 mrr: 0.081071	 ndcg_5: 0.0704	 ndcg_10: 0.0940	 hit@1:0.032000	 hit@5:0.1100	 hit@10: 0.1840
new best model saved.

2024-07-10 10:29:32.777574: step 5488/24010 (epoch 16/70), loss = 1.366828 (43.251 sec/epoch), lr: 0.000500
2024-07-10 10:30:16.009566: step 5831/24010 (epoch 17/70), loss = 1.353959 (43.232 sec/epoch), lr: 0.000500
2024-07-10 10:30:59.121560: step 6174/24010 (epoch 18/70), loss = 1.331070 (43.112 sec/epoch), lr: 0.000500
2024-07-10 10:31:42.394987: step 6517/24010 (epoch 19/70), loss = 1.316778 (43.273 sec/epoch), lr: 0.000500
2024-07-10 10:32:25.743070: step 6860/24010 (epoch 20/70), loss = 1.304097 (43.348 sec/epoch), lr: 0.000500
Evaluating on dev set...
....................
source: 	 mrr: 0.139992	 ndcg_5: 0.1295	 ndcg_10: 0.1653	 hit@1:0.056000	 hit@5:0.2010	 hit@10: 0.3140
target: 	 mrr: 0.126467	 ndcg_5: 0.1138	 ndcg_10: 0.1445	 hit@1:0.051000	 hit@5:0.1770	 hit@10: 0.2720
new best model saved.

2024-07-10 10:33:09.326446: step 7203/24010 (epoch 21/70), loss = 1.292145 (43.182 sec/epoch), lr: 0.000500
2024-07-10 10:33:52.670061: step 7546/24010 (epoch 22/70), loss = 1.283641 (43.344 sec/epoch), lr: 0.000500
2024-07-10 10:34:35.922254: step 7889/24010 (epoch 23/70), loss = 1.275274 (43.252 sec/epoch), lr: 0.000500
2024-07-10 10:35:19.182850: step 8232/24010 (epoch 24/70), loss = 1.266629 (43.261 sec/epoch), lr: 0.000500
2024-07-10 10:36:02.728611: step 8575/24010 (epoch 25/70), loss = 1.258876 (43.546 sec/epoch), lr: 0.000500
Evaluating on dev set...
....................
source: 	 mrr: 0.114647	 ndcg_5: 0.1054	 ndcg_10: 0.1334	 hit@1:0.039000	 hit@5:0.1740	 hit@10: 0.2610
target: 	 mrr: 0.153296	 ndcg_5: 0.1441	 ndcg_10: 0.1761	 hit@1:0.066000	 hit@5:0.2160	 hit@10: 0.3150
new best model saved.

2024-07-10 10:36:46.457457: step 8918/24010 (epoch 26/70), loss = 1.252762 (43.338 sec/epoch), lr: 0.000500
2024-07-10 10:37:29.727768: step 9261/24010 (epoch 27/70), loss = 1.246486 (43.270 sec/epoch), lr: 0.000500
2024-07-10 10:38:12.703992: step 9604/24010 (epoch 28/70), loss = 1.242336 (42.976 sec/epoch), lr: 0.000500
2024-07-10 10:38:55.935031: step 9947/24010 (epoch 29/70), loss = 1.237041 (43.231 sec/epoch), lr: 0.000500
2024-07-10 10:39:38.955330: step 10290/24010 (epoch 30/70), loss = 1.228975 (43.020 sec/epoch), lr: 0.000500
Evaluating on dev set...
....................
source: 	 mrr: 0.109814	 ndcg_5: 0.0969	 ndcg_10: 0.1285	 hit@1:0.045000	 hit@5:0.1500	 hit@10: 0.2490
target: 	 mrr: 0.151769	 ndcg_5: 0.1397	 ndcg_10: 0.1746	 hit@1:0.070000	 hit@5:0.2070	 hit@10: 0.3150

2024-07-10 10:40:22.573345: step 10633/24010 (epoch 31/70), loss = 1.222094 (43.397 sec/epoch), lr: 0.000475
2024-07-10 10:41:05.758940: step 10976/24010 (epoch 32/70), loss = 1.214194 (43.186 sec/epoch), lr: 0.000475
2024-07-10 10:41:48.953185: step 11319/24010 (epoch 33/70), loss = 1.212948 (43.194 sec/epoch), lr: 0.000475
2024-07-10 10:42:32.194166: step 11662/24010 (epoch 34/70), loss = 1.209267 (43.241 sec/epoch), lr: 0.000475
2024-07-10 10:43:15.378982: step 12005/24010 (epoch 35/70), loss = 1.201508 (43.185 sec/epoch), lr: 0.000475
Evaluating on dev set...
....................
source: 	 mrr: 0.202065	 ndcg_5: 0.1941	 ndcg_10: 0.2346	 hit@1:0.105000	 hit@5:0.2820	 hit@10: 0.4070
target: 	 mrr: 0.142815	 ndcg_5: 0.1364	 ndcg_10: 0.1689	 hit@1:0.052000	 hit@5:0.2210	 hit@10: 0.3210
new best model saved.

2024-07-10 10:43:58.902588: step 12348/24010 (epoch 36/70), loss = 1.203271 (43.119 sec/epoch), lr: 0.000475
2024-07-10 10:44:42.024882: step 12691/24010 (epoch 37/70), loss = 1.199180 (43.122 sec/epoch), lr: 0.000475
2024-07-10 10:45:25.307587: step 13034/24010 (epoch 38/70), loss = 1.193741 (43.283 sec/epoch), lr: 0.000475
2024-07-10 10:46:08.463237: step 13377/24010 (epoch 39/70), loss = 1.190580 (43.156 sec/epoch), lr: 0.000475
2024-07-10 10:46:51.650627: step 13720/24010 (epoch 40/70), loss = 1.186903 (43.187 sec/epoch), lr: 0.000475
Evaluating on dev set...
....................
source: 	 mrr: 0.119021	 ndcg_5: 0.1076	 ndcg_10: 0.1315	 hit@1:0.058000	 hit@5:0.1570	 hit@10: 0.2310
target: 	 mrr: 0.144397	 ndcg_5: 0.1277	 ndcg_10: 0.1671	 hit@1:0.069000	 hit@5:0.1870	 hit@10: 0.3080

2024-07-10 10:47:35.126779: step 14063/24010 (epoch 41/70), loss = 1.180209 (43.248 sec/epoch), lr: 0.000451
2024-07-10 10:48:18.324954: step 14406/24010 (epoch 42/70), loss = 1.176979 (43.198 sec/epoch), lr: 0.000451
2024-07-10 10:49:01.446592: step 14749/24010 (epoch 43/70), loss = 1.172769 (43.122 sec/epoch), lr: 0.000451
2024-07-10 10:49:44.674376: step 15092/24010 (epoch 44/70), loss = 1.170344 (43.228 sec/epoch), lr: 0.000451
2024-07-10 10:50:27.870757: step 15435/24010 (epoch 45/70), loss = 1.169360 (43.196 sec/epoch), lr: 0.000451
Evaluating on dev set...
....................
source: 	 mrr: 0.236667	 ndcg_5: 0.2313	 ndcg_10: 0.2842	 hit@1:0.123000	 hit@5:0.3380	 hit@10: 0.5020
target: 	 mrr: 0.103836	 ndcg_5: 0.0935	 ndcg_10: 0.1130	 hit@1:0.050000	 hit@5:0.1390	 hit@10: 0.1990

2024-07-10 10:51:11.342503: step 15778/24010 (epoch 46/70), loss = 1.164012 (43.250 sec/epoch), lr: 0.000451
2024-07-10 10:51:54.536950: step 16121/24010 (epoch 47/70), loss = 1.159937 (43.194 sec/epoch), lr: 0.000451
2024-07-10 10:52:37.849579: step 16464/24010 (epoch 48/70), loss = 1.158117 (43.313 sec/epoch), lr: 0.000451
2024-07-10 10:53:20.978582: step 16807/24010 (epoch 49/70), loss = 1.158685 (43.129 sec/epoch), lr: 0.000451
2024-07-10 10:54:04.108021: step 17150/24010 (epoch 50/70), loss = 1.155686 (43.129 sec/epoch), lr: 0.000451
Evaluating on dev set...
....................
source: 	 mrr: 0.202076	 ndcg_5: 0.1959	 ndcg_10: 0.2412	 hit@1:0.094000	 hit@5:0.2930	 hit@10: 0.4330
target: 	 mrr: 0.152876	 ndcg_5: 0.1391	 ndcg_10: 0.1735	 hit@1:0.069000	 hit@5:0.2090	 hit@10: 0.3160

2024-07-10 10:54:47.295690: step 17493/24010 (epoch 51/70), loss = 1.154947 (42.962 sec/epoch), lr: 0.000451
2024-07-10 10:55:30.448580: step 17836/24010 (epoch 52/70), loss = 1.149966 (43.153 sec/epoch), lr: 0.000451
2024-07-10 10:56:13.722980: step 18179/24010 (epoch 53/70), loss = 1.149829 (43.274 sec/epoch), lr: 0.000451
2024-07-10 10:56:57.379580: step 18522/24010 (epoch 54/70), loss = 1.147653 (43.657 sec/epoch), lr: 0.000451
2024-07-10 10:57:40.962127: step 18865/24010 (epoch 55/70), loss = 1.144490 (43.583 sec/epoch), lr: 0.000451
Evaluating on dev set...
....................
source: 	 mrr: 0.203813	 ndcg_5: 0.1999	 ndcg_10: 0.2423	 hit@1:0.093000	 hit@5:0.3000	 hit@10: 0.4310
target: 	 mrr: 0.224729	 ndcg_5: 0.2180	 ndcg_10: 0.2648	 hit@1:0.116000	 hit@5:0.3180	 hit@10: 0.4620
new best model saved.

2024-07-10 10:58:24.491869: step 19208/24010 (epoch 56/70), loss = 1.143879 (43.157 sec/epoch), lr: 0.000451
2024-07-10 10:59:07.801823: step 19551/24010 (epoch 57/70), loss = 1.139924 (43.310 sec/epoch), lr: 0.000451
2024-07-10 10:59:50.926946: step 19894/24010 (epoch 58/70), loss = 1.142744 (43.125 sec/epoch), lr: 0.000451
2024-07-10 11:00:34.255589: step 20237/24010 (epoch 59/70), loss = 1.140988 (43.329 sec/epoch), lr: 0.000451
2024-07-10 11:01:17.587708: step 20580/24010 (epoch 60/70), loss = 1.137457 (43.332 sec/epoch), lr: 0.000451
Evaluating on dev set...
....................
source: 	 mrr: 0.289386	 ndcg_5: 0.2929	 ndcg_10: 0.3386	 hit@1:0.162000	 hit@5:0.4150	 hit@10: 0.5550
target: 	 mrr: 0.201611	 ndcg_5: 0.1952	 ndcg_10: 0.2347	 hit@1:0.102000	 hit@5:0.2860	 hit@10: 0.4100
new best model saved.
shift to transfer learning mode

2024-07-10 11:04:37.200069: step 20923/24010 (epoch 61/70), loss = 1.393368 (199.067 sec/epoch), lr: 0.000500
2024-07-10 11:07:56.126981: step 21266/24010 (epoch 62/70), loss = 1.337925 (198.927 sec/epoch), lr: 0.000500
2024-07-10 11:11:15.228256: step 21609/24010 (epoch 63/70), loss = 1.318155 (199.101 sec/epoch), lr: 0.000500
2024-07-10 11:14:34.371521: step 21952/24010 (epoch 64/70), loss = 1.304404 (199.143 sec/epoch), lr: 0.000500
2024-07-10 11:17:53.411519: step 22295/24010 (epoch 65/70), loss = 1.287853 (199.040 sec/epoch), lr: 0.000500
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.050286	 ndcg_5: 0.0427	 ndcg_10: 0.0546	 hit@1:0.019962	 hit@5:0.0650	 hit@10: 0.1023
target: 	 mrr: 0.037591	 ndcg_5: 0.0307	 ndcg_10: 0.0406	 hit@1:0.010031	 hit@5:0.0521	 hit@10: 0.0830
epoch 65: train_loss = 1.287853, source_hit@10 = 0.1023, source_ndcg@10 = 0.0546, target_hit@10 = 0.0830, target_ndcg@10 = 0.0406

2024-07-10 11:21:13.349184: step 22638/24010 (epoch 66/70), loss = 1.280953 (199.000 sec/epoch), lr: 0.000475
2024-07-10 11:24:32.324032: step 22981/24010 (epoch 67/70), loss = 1.270690 (198.975 sec/epoch), lr: 0.000475
2024-07-10 11:27:51.401397: step 23324/24010 (epoch 68/70), loss = 1.263191 (199.077 sec/epoch), lr: 0.000475
2024-07-10 11:31:10.293207: step 23667/24010 (epoch 69/70), loss = 1.253484 (198.892 sec/epoch), lr: 0.000475
2024-07-10 11:34:29.301423: step 24010/24010 (epoch 70/70), loss = 1.243996 (199.008 sec/epoch), lr: 0.000475
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.037825	 ndcg_5: 0.0300	 ndcg_10: 0.0376	 hit@1:0.012674	 hit@5:0.0475	 hit@10: 0.0710
target: 	 mrr: 0.034528	 ndcg_5: 0.0265	 ndcg_10: 0.0367	 hit@1:0.010309	 hit@5:0.0426	 hit@10: 0.0738
epoch 70: train_loss = 1.243996, source_hit@10 = 0.0710, source_ndcg@10 = 0.0376, target_hit@10 = 0.0738, target_ndcg@10 = 0.0367

