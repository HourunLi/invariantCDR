nohup: ignoring input
using gpu:0 to train the model
using gpu:0 to train the model
cuda:0
Namespace(A_split=False, JK='sum', a_fold=100, aggregate=False, batch_size=1024, beta=1.5, conv_layers=4, cuda=True, decay_epoch=5, device=device(type='cuda', index=0), device_id='0', domains='game_video', dropout=0.2, epoch=70, feature_dim=126, hidden_dim=126, keep_prob=0.6, lambda_constra=0.3, lambda_critic=0.3, lambda_ease=50, leakey=0.01, load=True, log='logs.txt', log_epoch=1, lr=0.0005, lr_decay=0.95, lr_transfer=0.0005, min_epoch=50, mode='train', model_file='single_50.pt', model_name='gv_4', num_latent_factors=3, num_negative=10, optim='adam', patience=50, proj_layers=1, projection=1, residual=1, save=True, save_dir='./saved_models', seed=32, sim_threshold=0.9, tau=0.4, test_sample_number=999, transfer_epoch=50, user_batch_size=256, weight_decay=0.0002)
number_user 25025
number_item 12319
/home/hourun/invariantCDR_v2/invariantCDR/utils/GraphMaker.py:47: RuntimeWarning: divide by zero encountered in power
  r_inv = np.power(rowsum, -1).flatten()
real graph loaded!
augmented graph loaded!
number_user 19457
number_item 8751
real graph loaded!
augmented graph loaded!
graph loaded!
Loading data from game_video with batch size 1024...
unseen test: 0
test length: 1381
unseen test: 0
test length: 1304
unseen test: 0
test length: 1435
unseen test: 0
test length: 1458
source_user_num 25025
target_user_num 19457
source_item_num 12319
target_item_num 8751
shared users id: 1737
test users 226, 217
unseen test: 0
dev length: 1000
unseen test: 0
dev length: 1000
source train data : 155036, target train data: 156091, source test data : 1304, target test data : 1458, source dev data : 1000, target dev data : 1000
Loading model from ./saved_models/gv_4/single_50.pt
2024-07-11 10:46:38.729208: step 304/21280 (epoch 50/70), loss = 0.544403 (18.143 sec/epoch), lr: 0.000500
Evaluating on dev set...
....................
source: 	 mrr: 0.202616	 ndcg_5: 0.1976	 ndcg_10: 0.2381	 hit@1:0.094000	 hit@5:0.2970	 hit@10: 0.4230
target: 	 mrr: 0.244293	 ndcg_5: 0.2357	 ndcg_10: 0.2975	 hit@1:0.116000	 hit@5:0.3500	 hit@10: 0.5400
new best model saved.

2024-07-11 10:46:56.658592: step 608/21280 (epoch 51/70), loss = 0.498041 (17.648 sec/epoch), lr: 0.000500
Evaluating on dev set...
...........................
source: 	 mrr: 0.042893	 ndcg_5: 0.0326	 ndcg_10: 0.0432	 hit@1:0.014482	 hit@5:0.0514	 hit@10: 0.0847
target: 	 mrr: 0.057472	 ndcg_5: 0.0510	 ndcg_10: 0.0632	 hit@1:0.019512	 hit@5:0.0815	 hit@10: 0.1199
epoch 51: train_loss = 0.498041, source_hit@10 = 0.0847, source_ndcg@10 = 0.0432, target_hit@10 = 0.1199, target_ndcg@10 = 0.0632

2024-07-11 10:47:14.590023: step 912/21280 (epoch 52/70), loss = 0.471385 (17.668 sec/epoch), lr: 0.000475
Evaluating on dev set...
...........................
source: 	 mrr: 0.041691	 ndcg_5: 0.0312	 ndcg_10: 0.0405	 hit@1:0.015206	 hit@5:0.0471	 hit@10: 0.0760
target: 	 mrr: 0.059187	 ndcg_5: 0.0503	 ndcg_10: 0.0645	 hit@1:0.023693	 hit@5:0.0760	 hit@10: 0.1206
epoch 52: train_loss = 0.471385, source_hit@10 = 0.0760, source_ndcg@10 = 0.0405, target_hit@10 = 0.1206, target_ndcg@10 = 0.0645

2024-07-11 10:47:32.515558: step 1216/21280 (epoch 53/70), loss = 0.460037 (17.669 sec/epoch), lr: 0.000475
Evaluating on dev set...
...........................
source: 	 mrr: 0.043257	 ndcg_5: 0.0319	 ndcg_10: 0.0447	 hit@1:0.013034	 hit@5:0.0514	 hit@10: 0.0920
target: 	 mrr: 0.062567	 ndcg_5: 0.0568	 ndcg_10: 0.0692	 hit@1:0.023693	 hit@5:0.0878	 hit@10: 0.1261
epoch 53: train_loss = 0.460037, source_hit@10 = 0.0920, source_ndcg@10 = 0.0447, target_hit@10 = 0.1261, target_ndcg@10 = 0.0692

2024-07-11 10:47:50.441248: step 1520/21280 (epoch 54/70), loss = 0.446112 (17.668 sec/epoch), lr: 0.000475
Evaluating on dev set...
...........................
source: 	 mrr: 0.035328	 ndcg_5: 0.0254	 ndcg_10: 0.0339	 hit@1:0.011586	 hit@5:0.0398	 hit@10: 0.0659
target: 	 mrr: 0.051975	 ndcg_5: 0.0433	 ndcg_10: 0.0549	 hit@1:0.020209	 hit@5:0.0669	 hit@10: 0.1031
epoch 54: train_loss = 0.446112, source_hit@10 = 0.0659, source_ndcg@10 = 0.0339, target_hit@10 = 0.1031, target_ndcg@10 = 0.0549

2024-07-11 10:48:08.364508: step 1824/21280 (epoch 55/70), loss = 0.429373 (17.667 sec/epoch), lr: 0.000451
Evaluating on dev set...
...........................
source: 	 mrr: 0.035226	 ndcg_5: 0.0259	 ndcg_10: 0.0367	 hit@1:0.006517	 hit@5:0.0478	 hit@10: 0.0818
target: 	 mrr: 0.066657	 ndcg_5: 0.0573	 ndcg_10: 0.0720	 hit@1:0.030662	 hit@5:0.0815	 hit@10: 0.1268
epoch 55: train_loss = 0.429373, source_hit@10 = 0.0818, source_ndcg@10 = 0.0367, target_hit@10 = 0.1268, target_ndcg@10 = 0.0720

2024-07-11 10:48:26.292075: step 2128/21280 (epoch 56/70), loss = 0.418512 (17.671 sec/epoch), lr: 0.000451
Evaluating on dev set...
...........................
source: 	 mrr: 0.039068	 ndcg_5: 0.0276	 ndcg_10: 0.0403	 hit@1:0.010862	 hit@5:0.0427	 hit@10: 0.0825
target: 	 mrr: 0.055295	 ndcg_5: 0.0458	 ndcg_10: 0.0572	 hit@1:0.025087	 hit@5:0.0662	 hit@10: 0.1017
epoch 56: train_loss = 0.418512, source_hit@10 = 0.0825, source_ndcg@10 = 0.0403, target_hit@10 = 0.1017, target_ndcg@10 = 0.0572

2024-07-11 10:48:44.231680: step 2432/21280 (epoch 57/70), loss = 0.413964 (17.683 sec/epoch), lr: 0.000429
Evaluating on dev set...
...........................
source: 	 mrr: 0.041208	 ndcg_5: 0.0310	 ndcg_10: 0.0412	 hit@1:0.010862	 hit@5:0.0514	 hit@10: 0.0833
target: 	 mrr: 0.055407	 ndcg_5: 0.0454	 ndcg_10: 0.0583	 hit@1:0.027178	 hit@5:0.0641	 hit@10: 0.1045
epoch 57: train_loss = 0.413964, source_hit@10 = 0.0833, source_ndcg@10 = 0.0412, target_hit@10 = 0.1045, target_ndcg@10 = 0.0583

2024-07-11 10:49:02.169371: step 2736/21280 (epoch 58/70), loss = 0.403087 (17.680 sec/epoch), lr: 0.000429
Evaluating on dev set...
...........................
source: 	 mrr: 0.037596	 ndcg_5: 0.0278	 ndcg_10: 0.0374	 hit@1:0.009413	 hit@5:0.0463	 hit@10: 0.0768
target: 	 mrr: 0.047373	 ndcg_5: 0.0391	 ndcg_10: 0.0521	 hit@1:0.014634	 hit@5:0.0634	 hit@10: 0.1038
epoch 58: train_loss = 0.403087, source_hit@10 = 0.0768, source_ndcg@10 = 0.0374, target_hit@10 = 0.1038, target_ndcg@10 = 0.0521

2024-07-11 10:49:20.093004: step 3040/21280 (epoch 59/70), loss = 0.396507 (17.666 sec/epoch), lr: 0.000407
Evaluating on dev set...
...........................
source: 	 mrr: 0.040633	 ndcg_5: 0.0291	 ndcg_10: 0.0407	 hit@1:0.010862	 hit@5:0.0456	 hit@10: 0.0818
target: 	 mrr: 0.056724	 ndcg_5: 0.0487	 ndcg_10: 0.0631	 hit@1:0.020906	 hit@5:0.0760	 hit@10: 0.1206
epoch 59: train_loss = 0.396507, source_hit@10 = 0.0818, source_ndcg@10 = 0.0407, target_hit@10 = 0.1206, target_ndcg@10 = 0.0631

2024-07-11 10:49:38.034420: step 3344/21280 (epoch 60/70), loss = 0.391742 (17.684 sec/epoch), lr: 0.000407
Evaluating on dev set...
...........................
source: 	 mrr: 0.035488	 ndcg_5: 0.0239	 ndcg_10: 0.0369	 hit@1:0.009413	 hit@5:0.0391	 hit@10: 0.0797
target: 	 mrr: 0.055519	 ndcg_5: 0.0467	 ndcg_10: 0.0600	 hit@1:0.023693	 hit@5:0.0704	 hit@10: 0.1115
epoch 60: train_loss = 0.391742, source_hit@10 = 0.0797, source_ndcg@10 = 0.0369, target_hit@10 = 0.1115, target_ndcg@10 = 0.0600

2024-07-11 10:49:55.992039: step 3648/21280 (epoch 61/70), loss = 0.385008 (17.699 sec/epoch), lr: 0.000387
Evaluating on dev set...
...........................
source: 	 mrr: 0.039589	 ndcg_5: 0.0277	 ndcg_10: 0.0398	 hit@1:0.013034	 hit@5:0.0427	 hit@10: 0.0804
target: 	 mrr: 0.062482	 ndcg_5: 0.0572	 ndcg_10: 0.0691	 hit@1:0.023693	 hit@5:0.0899	 hit@10: 0.1268
epoch 61: train_loss = 0.385008, source_hit@10 = 0.0804, source_ndcg@10 = 0.0398, target_hit@10 = 0.1268, target_ndcg@10 = 0.0691

2024-07-11 10:50:13.960853: step 3952/21280 (epoch 62/70), loss = 0.377734 (17.710 sec/epoch), lr: 0.000387
Evaluating on dev set...
...........................
source: 	 mrr: 0.035179	 ndcg_5: 0.0256	 ndcg_10: 0.0335	 hit@1:0.010862	 hit@5:0.0406	 hit@10: 0.0652
target: 	 mrr: 0.051898	 ndcg_5: 0.0455	 ndcg_10: 0.0599	 hit@1:0.016725	 hit@5:0.0725	 hit@10: 0.1178
epoch 62: train_loss = 0.377734, source_hit@10 = 0.0652, source_ndcg@10 = 0.0335, target_hit@10 = 0.1178, target_ndcg@10 = 0.0599

2024-07-11 10:50:31.904219: step 4256/21280 (epoch 63/70), loss = 0.369090 (17.684 sec/epoch), lr: 0.000368
Evaluating on dev set...
...........................
source: 	 mrr: 0.037453	 ndcg_5: 0.0254	 ndcg_10: 0.0342	 hit@1:0.013034	 hit@5:0.0377	 hit@10: 0.0652
target: 	 mrr: 0.055644	 ndcg_5: 0.0473	 ndcg_10: 0.0598	 hit@1:0.022997	 hit@5:0.0711	 hit@10: 0.1101
epoch 63: train_loss = 0.369090, source_hit@10 = 0.0652, source_ndcg@10 = 0.0342, target_hit@10 = 0.1101, target_ndcg@10 = 0.0598

2024-07-11 10:50:49.818740: step 4560/21280 (epoch 64/70), loss = 0.366132 (17.654 sec/epoch), lr: 0.000368
Evaluating on dev set...
...........................
source: 	 mrr: 0.037258	 ndcg_5: 0.0265	 ndcg_10: 0.0348	 hit@1:0.012310	 hit@5:0.0413	 hit@10: 0.0673
target: 	 mrr: 0.057423	 ndcg_5: 0.0509	 ndcg_10: 0.0613	 hit@1:0.024390	 hit@5:0.0760	 hit@10: 0.1087
epoch 64: train_loss = 0.366132, source_hit@10 = 0.0673, source_ndcg@10 = 0.0348, target_hit@10 = 0.1087, target_ndcg@10 = 0.0613

2024-07-11 10:51:07.732812: step 4864/21280 (epoch 65/70), loss = 0.364276 (17.656 sec/epoch), lr: 0.000368
Evaluating on dev set...
...........................
source: 	 mrr: 0.038543	 ndcg_5: 0.0267	 ndcg_10: 0.0368	 hit@1:0.013034	 hit@5:0.0398	 hit@10: 0.0710
target: 	 mrr: 0.050979	 ndcg_5: 0.0417	 ndcg_10: 0.0545	 hit@1:0.020906	 hit@5:0.0620	 hit@10: 0.1024
epoch 65: train_loss = 0.364276, source_hit@10 = 0.0710, source_ndcg@10 = 0.0368, target_hit@10 = 0.1024, target_ndcg@10 = 0.0545

2024-07-11 10:51:25.648053: step 5168/21280 (epoch 66/70), loss = 0.357257 (17.659 sec/epoch), lr: 0.000349
Evaluating on dev set...
...........................
source: 	 mrr: 0.044424	 ndcg_5: 0.0329	 ndcg_10: 0.0436	 hit@1:0.018827	 hit@5:0.0478	 hit@10: 0.0811
target: 	 mrr: 0.052808	 ndcg_5: 0.0446	 ndcg_10: 0.0575	 hit@1:0.022300	 hit@5:0.0676	 hit@10: 0.1080
epoch 66: train_loss = 0.357257, source_hit@10 = 0.0811, source_ndcg@10 = 0.0436, target_hit@10 = 0.1080, target_ndcg@10 = 0.0575

2024-07-11 10:51:43.563581: step 5472/21280 (epoch 67/70), loss = 0.350131 (17.659 sec/epoch), lr: 0.000349
Evaluating on dev set...
...........................
source: 	 mrr: 0.032638	 ndcg_5: 0.0210	 ndcg_10: 0.0312	 hit@1:0.009413	 hit@5:0.0311	 hit@10: 0.0630
target: 	 mrr: 0.053063	 ndcg_5: 0.0463	 ndcg_10: 0.0571	 hit@1:0.020209	 hit@5:0.0718	 hit@10: 0.1059
epoch 67: train_loss = 0.350131, source_hit@10 = 0.0630, source_ndcg@10 = 0.0312, target_hit@10 = 0.1059, target_ndcg@10 = 0.0571

2024-07-11 10:52:01.481677: step 5776/21280 (epoch 68/70), loss = 0.342980 (17.661 sec/epoch), lr: 0.000332
Evaluating on dev set...
...........................
source: 	 mrr: 0.037526	 ndcg_5: 0.0261	 ndcg_10: 0.0370	 hit@1:0.012310	 hit@5:0.0413	 hit@10: 0.0753
target: 	 mrr: 0.048165	 ndcg_5: 0.0386	 ndcg_10: 0.0478	 hit@1:0.020906	 hit@5:0.0557	 hit@10: 0.0843
epoch 68: train_loss = 0.342980, source_hit@10 = 0.0753, source_ndcg@10 = 0.0370, target_hit@10 = 0.0843, target_ndcg@10 = 0.0478

2024-07-11 10:52:19.401299: step 6080/21280 (epoch 69/70), loss = 0.340344 (17.663 sec/epoch), lr: 0.000315
Evaluating on dev set...
...........................
source: 	 mrr: 0.035246	 ndcg_5: 0.0253	 ndcg_10: 0.0366	 hit@1:0.007241	 hit@5:0.0434	 hit@10: 0.0789
target: 	 mrr: 0.054733	 ndcg_5: 0.0471	 ndcg_10: 0.0581	 hit@1:0.025087	 hit@5:0.0704	 hit@10: 0.1052
epoch 69: train_loss = 0.340344, source_hit@10 = 0.0789, source_ndcg@10 = 0.0366, target_hit@10 = 0.1052, target_ndcg@10 = 0.0581

2024-07-11 10:52:37.318869: step 6384/21280 (epoch 70/70), loss = 0.333163 (17.661 sec/epoch), lr: 0.000315
Evaluating on dev set...
...........................
source: 	 mrr: 0.039369	 ndcg_5: 0.0280	 ndcg_10: 0.0401	 hit@1:0.012310	 hit@5:0.0442	 hit@10: 0.0825
target: 	 mrr: 0.048154	 ndcg_5: 0.0389	 ndcg_10: 0.0508	 hit@1:0.018815	 hit@5:0.0599	 hit@10: 0.0969
epoch 70: train_loss = 0.333163, source_hit@10 = 0.0825, source_ndcg@10 = 0.0401, target_hit@10 = 0.0969, target_ndcg@10 = 0.0508

