nohup: ignoring input
using gpu:1 to train the model
using gpu:1 to train the model
cuda:1
Namespace(A_split=False, JK='sum', a_fold=100, aggregate=False, alpha=0.5, batch_size=1024, beta_inter=0.5, conv_layers=4, cuda=True, decay_epoch=10, device=device(type='cuda', index=1), device_id='1', domains='cloth_sport', dropout=0.5, epoch=80, feature_dim=126, hidden_dim=126, inter_tau=0.2, intra_tau=1, lambda_critic=0.4, leakey=0.05, load=False, log='logs.txt', log_epoch=1, lr=0.004, lr_decay=0.95, min_epoch=50, mode='train', model_file=None, model_name='cs', momentum=0.9, num_latent_factors=3, num_negative=100, optim='adam', patience=30, proj_layers=1, projection=1, residual=1, save=False, save_dir='./saved_models', seed=2040, similarity_tau=0.1, test_sample_number=999, transfer_epoch=40, user_batch_size=256, weight_decay=0.0002)
number_user 41829
number_item 17943
/home/hourun/invariantCDR_v2/invariantCDR/utils/GraphMaker.py:46: RuntimeWarning: divide by zero encountered in power
  r_inv = np.power(rowsum, -1).flatten()
real graph loaded!
number_user 27328
number_item 12655
real graph loaded!
graph loaded!
Loading data from cloth_sport with batch size 1024...
unseen test: 0
test length: 3156
unseen test: 0
test length: 3085
unseen test: 0
test length: 3589
unseen test: 0
test length: 3546
source_user_num 41829
target_user_num 27328
source_item_num 17943
target_item_num 12655
shared users id: 7857
test users 990, 982
unseen test: 0
dev length: 1000
unseen test: 0
dev length: 1000
source train data : 187880, target train data: 163291, source test data : 3085, target test data : 3546, source dev data : 1000, target dev data : 1000
2024-08-03 12:04:48.335602: step 343/27440 (epoch 1/80), loss = 1.426262 (51.118 sec/epoch), lr: 0.004000
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.033852	 ndcg_5: 0.0254	 ndcg_10: 0.0346	 hit@1:0.009823	 hit@5:0.0418	 hit@10: 0.0707
target: 	 mrr: 0.017083	 ndcg_5: 0.0128	 ndcg_10: 0.0167	 hit@1:0.003901	 hit@5:0.0212	 hit@10: 0.0334
source best!
..............................
source: 	 mrr: 0.030235	 ndcg_5: 0.0211	 ndcg_10: 0.0302	 hit@1:0.008104	 hit@5:0.0347	 hit@10: 0.0629
target best!
...................................target: 	 mrr: 0.018521	 ndcg_5: 0.0136	 ndcg_10: 0.0175	 hit@1:0.006486	 hit@5:0.0209	 hit@10: 0.0330
epoch 1: train_loss = 1.426262, source_hit@10 = 0.0629, source_ndcg@10 = 0.0302, target_hit@10 = 0.0330, target_ndcg@10 = 0.0175

2024-08-03 12:05:40.163445: step 686/27440 (epoch 2/80), loss = 1.273912 (50.361 sec/epoch), lr: 0.004000
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.042271	 ndcg_5: 0.0327	 ndcg_10: 0.0446	 hit@1:0.013942	 hit@5:0.0501	 hit@10: 0.0875
target: 	 mrr: 0.032476	 ndcg_5: 0.0243	 ndcg_10: 0.0344	 hit@1:0.007802	 hit@5:0.0426	 hit@10: 0.0741
source best!
..............................
source: 	 mrr: 0.037175	 ndcg_5: 0.0275	 ndcg_10: 0.0394	 hit@1:0.012318	 hit@5:0.0431	 hit@10: 0.0801
target best!
...................................target: 	 mrr: 0.033490	 ndcg_5: 0.0246	 ndcg_10: 0.0349	 hit@1:0.008742	 hit@5:0.0403	 hit@10: 0.0722
epoch 2: train_loss = 1.273912, source_hit@10 = 0.0801, source_ndcg@10 = 0.0394, target_hit@10 = 0.0722, target_ndcg@10 = 0.0349
new best model saved.

2024-08-03 12:06:32.187669: step 1029/27440 (epoch 3/80), loss = 1.262069 (50.421 sec/epoch), lr: 0.004000
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.044866	 ndcg_5: 0.0377	 ndcg_10: 0.0483	 hit@1:0.015843	 hit@5:0.0605	 hit@10: 0.0938
target: 	 mrr: 0.029685	 ndcg_5: 0.0196	 ndcg_10: 0.0295	 hit@1:0.006687	 hit@5:0.0323	 hit@10: 0.0632
source best!
..............................
source: 	 mrr: 0.042691	 ndcg_5: 0.0364	 ndcg_10: 0.0467	 hit@1:0.012966	 hit@5:0.0596	 hit@10: 0.0917
epoch 3: train_loss = 1.262069, source_hit@10 = 0.0917, source_ndcg@10 = 0.0467, target_hit@10 = 0.0632, target_ndcg@10 = 0.0295

2024-08-03 12:07:23.559203: step 1372/27440 (epoch 4/80), loss = 1.254987 (50.327 sec/epoch), lr: 0.004000
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.042152	 ndcg_5: 0.0333	 ndcg_10: 0.0457	 hit@1:0.014259	 hit@5:0.0535	 hit@10: 0.0922
target: 	 mrr: 0.031318	 ndcg_5: 0.0223	 ndcg_10: 0.0319	 hit@1:0.008916	 hit@5:0.0359	 hit@10: 0.0655
epoch 4: train_loss = 1.254987, source_hit@10 = 0.0922, source_ndcg@10 = 0.0457, target_hit@10 = 0.0655, target_ndcg@10 = 0.0319

2024-08-03 12:08:14.526934: step 1715/27440 (epoch 5/80), loss = 1.245803 (50.227 sec/epoch), lr: 0.004000
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.040667	 ndcg_5: 0.0338	 ndcg_10: 0.0443	 hit@1:0.011090	 hit@5:0.0570	 hit@10: 0.0897
target: 	 mrr: 0.036540	 ndcg_5: 0.0282	 ndcg_10: 0.0390	 hit@1:0.011702	 hit@5:0.0457	 hit@10: 0.0791
target best!
...................................target: 	 mrr: 0.035313	 ndcg_5: 0.0261	 ndcg_10: 0.0369	 hit@1:0.010998	 hit@5:0.0415	 hit@10: 0.0750
epoch 5: train_loss = 1.245803, source_hit@10 = 0.0897, source_ndcg@10 = 0.0443, target_hit@10 = 0.0750, target_ndcg@10 = 0.0369

2024-08-03 12:09:06.087037: step 2058/27440 (epoch 6/80), loss = 1.228690 (50.474 sec/epoch), lr: 0.004000
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.037211	 ndcg_5: 0.0285	 ndcg_10: 0.0399	 hit@1:0.009506	 hit@5:0.0478	 hit@10: 0.0830
target: 	 mrr: 0.033949	 ndcg_5: 0.0259	 ndcg_10: 0.0355	 hit@1:0.008359	 hit@5:0.0435	 hit@10: 0.0730
epoch 6: train_loss = 1.228690, source_hit@10 = 0.0830, source_ndcg@10 = 0.0399, target_hit@10 = 0.0730, target_ndcg@10 = 0.0355

2024-08-03 12:09:57.042319: step 2401/27440 (epoch 7/80), loss = 1.227174 (50.214 sec/epoch), lr: 0.004000
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.040309	 ndcg_5: 0.0322	 ndcg_10: 0.0444	 hit@1:0.011724	 hit@5:0.0545	 hit@10: 0.0925
target: 	 mrr: 0.037215	 ndcg_5: 0.0304	 ndcg_10: 0.0394	 hit@1:0.011145	 hit@5:0.0502	 hit@10: 0.0783
target best!
...................................target: 	 mrr: 0.035989	 ndcg_5: 0.0282	 ndcg_10: 0.0371	 hit@1:0.011280	 hit@5:0.0462	 hit@10: 0.0736
epoch 7: train_loss = 1.227174, source_hit@10 = 0.0925, source_ndcg@10 = 0.0444, target_hit@10 = 0.0736, target_ndcg@10 = 0.0371

2024-08-03 12:10:48.670572: step 2744/27440 (epoch 8/80), loss = 1.223267 (50.515 sec/epoch), lr: 0.004000
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.041009	 ndcg_5: 0.0322	 ndcg_10: 0.0442	 hit@1:0.013308	 hit@5:0.0513	 hit@10: 0.0887
target: 	 mrr: 0.036583	 ndcg_5: 0.0287	 ndcg_10: 0.0372	 hit@1:0.011702	 hit@5:0.0460	 hit@10: 0.0724
epoch 8: train_loss = 1.223267, source_hit@10 = 0.0887, source_ndcg@10 = 0.0442, target_hit@10 = 0.0724, target_ndcg@10 = 0.0372

2024-08-03 12:11:40.184333: step 3087/27440 (epoch 9/80), loss = 1.221102 (50.775 sec/epoch), lr: 0.004000
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.035935	 ndcg_5: 0.0264	 ndcg_10: 0.0380	 hit@1:0.008555	 hit@5:0.0437	 hit@10: 0.0795
target: 	 mrr: 0.032457	 ndcg_5: 0.0248	 ndcg_10: 0.0318	 hit@1:0.011981	 hit@5:0.0376	 hit@10: 0.0596
epoch 9: train_loss = 1.221102, source_hit@10 = 0.0795, source_ndcg@10 = 0.0380, target_hit@10 = 0.0596, target_ndcg@10 = 0.0318

2024-08-03 12:12:31.517324: step 3430/27440 (epoch 10/80), loss = 1.213165 (50.591 sec/epoch), lr: 0.004000
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.039766	 ndcg_5: 0.0304	 ndcg_10: 0.0422	 hit@1:0.012357	 hit@5:0.0485	 hit@10: 0.0849
target: 	 mrr: 0.028224	 ndcg_5: 0.0197	 ndcg_10: 0.0294	 hit@1:0.007244	 hit@5:0.0326	 hit@10: 0.0630
epoch 10: train_loss = 1.213165, source_hit@10 = 0.0849, source_ndcg@10 = 0.0422, target_hit@10 = 0.0630, target_ndcg@10 = 0.0294

2024-08-03 12:13:22.731859: step 3773/27440 (epoch 11/80), loss = 1.203208 (50.448 sec/epoch), lr: 0.004000
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.041141	 ndcg_5: 0.0324	 ndcg_10: 0.0439	 hit@1:0.012357	 hit@5:0.0526	 hit@10: 0.0884
target: 	 mrr: 0.033194	 ndcg_5: 0.0258	 ndcg_10: 0.0332	 hit@1:0.010588	 hit@5:0.0410	 hit@10: 0.0635
epoch 11: train_loss = 1.203208, source_hit@10 = 0.0884, source_ndcg@10 = 0.0439, target_hit@10 = 0.0635, target_ndcg@10 = 0.0332

2024-08-03 12:14:13.980554: step 4116/27440 (epoch 12/80), loss = 1.190501 (50.459 sec/epoch), lr: 0.004000
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.049459	 ndcg_5: 0.0400	 ndcg_10: 0.0522	 hit@1:0.020596	 hit@5:0.0586	 hit@10: 0.0957
target: 	 mrr: 0.035393	 ndcg_5: 0.0255	 ndcg_10: 0.0376	 hit@1:0.009473	 hit@5:0.0410	 hit@10: 0.0786
source best!
..............................
source: 	 mrr: 0.045648	 ndcg_5: 0.0366	 ndcg_10: 0.0478	 hit@1:0.018801	 hit@5:0.0551	 hit@10: 0.0901
epoch 12: train_loss = 1.190501, source_hit@10 = 0.0901, source_ndcg@10 = 0.0478, target_hit@10 = 0.0786, target_ndcg@10 = 0.0376
new best model saved.

2024-08-03 12:15:05.757659: step 4459/27440 (epoch 13/80), loss = 1.176276 (50.404 sec/epoch), lr: 0.004000
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.043501	 ndcg_5: 0.0355	 ndcg_10: 0.0480	 hit@1:0.012357	 hit@5:0.0586	 hit@10: 0.0970
target: 	 mrr: 0.033391	 ndcg_5: 0.0264	 ndcg_10: 0.0344	 hit@1:0.010309	 hit@5:0.0426	 hit@10: 0.0677
epoch 13: train_loss = 1.176276, source_hit@10 = 0.0970, source_ndcg@10 = 0.0480, target_hit@10 = 0.0677, target_ndcg@10 = 0.0344

2024-08-03 12:15:56.924368: step 4802/27440 (epoch 14/80), loss = 1.165586 (50.430 sec/epoch), lr: 0.003800
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.043696	 ndcg_5: 0.0343	 ndcg_10: 0.0457	 hit@1:0.015843	 hit@5:0.0526	 hit@10: 0.0881
target: 	 mrr: 0.041169	 ndcg_5: 0.0333	 ndcg_10: 0.0449	 hit@1:0.014489	 hit@5:0.0515	 hit@10: 0.0878
target best!
...................................target: 	 mrr: 0.039097	 ndcg_5: 0.0314	 ndcg_10: 0.0422	 hit@1:0.013536	 hit@5:0.0488	 hit@10: 0.0829
epoch 14: train_loss = 1.165586, source_hit@10 = 0.0881, source_ndcg@10 = 0.0457, target_hit@10 = 0.0829, target_ndcg@10 = 0.0422

2024-08-03 12:16:48.259687: step 5145/27440 (epoch 15/80), loss = 1.157370 (50.240 sec/epoch), lr: 0.003800
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.043480	 ndcg_5: 0.0346	 ndcg_10: 0.0470	 hit@1:0.015209	 hit@5:0.0551	 hit@10: 0.0944
target: 	 mrr: 0.039218	 ndcg_5: 0.0303	 ndcg_10: 0.0411	 hit@1:0.011981	 hit@5:0.0479	 hit@10: 0.0814
epoch 15: train_loss = 1.157370, source_hit@10 = 0.0944, source_ndcg@10 = 0.0470, target_hit@10 = 0.0814, target_ndcg@10 = 0.0411

2024-08-03 12:17:40.090126: step 5488/27440 (epoch 16/80), loss = 1.154478 (51.093 sec/epoch), lr: 0.003610
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.042855	 ndcg_5: 0.0354	 ndcg_10: 0.0480	 hit@1:0.013625	 hit@5:0.0586	 hit@10: 0.0985
target: 	 mrr: 0.036046	 ndcg_5: 0.0280	 ndcg_10: 0.0375	 hit@1:0.009473	 hit@5:0.0460	 hit@10: 0.0755
epoch 16: train_loss = 1.154478, source_hit@10 = 0.0985, source_ndcg@10 = 0.0480, target_hit@10 = 0.0755, target_ndcg@10 = 0.0375

2024-08-03 12:18:31.472937: step 5831/27440 (epoch 17/80), loss = 1.147870 (50.636 sec/epoch), lr: 0.003429
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.044104	 ndcg_5: 0.0363	 ndcg_10: 0.0478	 hit@1:0.015209	 hit@5:0.0577	 hit@10: 0.0938
target: 	 mrr: 0.038324	 ndcg_5: 0.0285	 ndcg_10: 0.0405	 hit@1:0.012817	 hit@5:0.0446	 hit@10: 0.0816
epoch 17: train_loss = 1.147870, source_hit@10 = 0.0938, source_ndcg@10 = 0.0478, target_hit@10 = 0.0816, target_ndcg@10 = 0.0405

2024-08-03 12:19:22.837471: step 6174/27440 (epoch 18/80), loss = 1.137451 (50.598 sec/epoch), lr: 0.003429
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.033149	 ndcg_5: 0.0252	 ndcg_10: 0.0354	 hit@1:0.009506	 hit@5:0.0418	 hit@10: 0.0741
target: 	 mrr: 0.035932	 ndcg_5: 0.0275	 ndcg_10: 0.0377	 hit@1:0.011424	 hit@5:0.0437	 hit@10: 0.0752
epoch 18: train_loss = 1.137451, source_hit@10 = 0.0741, source_ndcg@10 = 0.0354, target_hit@10 = 0.0752, target_ndcg@10 = 0.0377

2024-08-03 12:20:14.083690: step 6517/27440 (epoch 19/80), loss = 1.131430 (50.477 sec/epoch), lr: 0.003258
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.041650	 ndcg_5: 0.0317	 ndcg_10: 0.0466	 hit@1:0.012991	 hit@5:0.0513	 hit@10: 0.0973
target: 	 mrr: 0.038014	 ndcg_5: 0.0295	 ndcg_10: 0.0390	 hit@1:0.012817	 hit@5:0.0476	 hit@10: 0.0769
epoch 19: train_loss = 1.131430, source_hit@10 = 0.0973, source_ndcg@10 = 0.0466, target_hit@10 = 0.0769, target_ndcg@10 = 0.0390

2024-08-03 12:21:05.399061: step 6860/27440 (epoch 20/80), loss = 1.129617 (50.575 sec/epoch), lr: 0.003258
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.039170	 ndcg_5: 0.0307	 ndcg_10: 0.0426	 hit@1:0.011407	 hit@5:0.0513	 hit@10: 0.0884
target: 	 mrr: 0.042325	 ndcg_5: 0.0329	 ndcg_10: 0.0442	 hit@1:0.016160	 hit@5:0.0504	 hit@10: 0.0855
target best!
...................................target: 	 mrr: 0.038598	 ndcg_5: 0.0300	 ndcg_10: 0.0397	 hit@1:0.012408	 hit@5:0.0477	 hit@10: 0.0778
epoch 20: train_loss = 1.129617, source_hit@10 = 0.0884, source_ndcg@10 = 0.0426, target_hit@10 = 0.0778, target_ndcg@10 = 0.0397

2024-08-03 12:21:57.399581: step 7203/27440 (epoch 21/80), loss = 1.126677 (50.908 sec/epoch), lr: 0.003258
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.047508	 ndcg_5: 0.0388	 ndcg_10: 0.0502	 hit@1:0.018061	 hit@5:0.0593	 hit@10: 0.0951
target: 	 mrr: 0.036780	 ndcg_5: 0.0267	 ndcg_10: 0.0377	 hit@1:0.010867	 hit@5:0.0415	 hit@10: 0.0761
epoch 21: train_loss = 1.126677, source_hit@10 = 0.0951, source_ndcg@10 = 0.0502, target_hit@10 = 0.0761, target_ndcg@10 = 0.0377

2024-08-03 12:22:48.934691: step 7546/27440 (epoch 22/80), loss = 1.129008 (50.792 sec/epoch), lr: 0.003258
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.038814	 ndcg_5: 0.0308	 ndcg_10: 0.0411	 hit@1:0.011407	 hit@5:0.0485	 hit@10: 0.0805
target: 	 mrr: 0.037856	 ndcg_5: 0.0297	 ndcg_10: 0.0392	 hit@1:0.011424	 hit@5:0.0488	 hit@10: 0.0783
epoch 22: train_loss = 1.129008, source_hit@10 = 0.0805, source_ndcg@10 = 0.0411, target_hit@10 = 0.0783, target_ndcg@10 = 0.0392

2024-08-03 12:23:40.390689: step 7889/27440 (epoch 23/80), loss = 1.122849 (50.716 sec/epoch), lr: 0.003095
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.039306	 ndcg_5: 0.0306	 ndcg_10: 0.0409	 hit@1:0.011724	 hit@5:0.0504	 hit@10: 0.0827
target: 	 mrr: 0.035580	 ndcg_5: 0.0257	 ndcg_10: 0.0376	 hit@1:0.009473	 hit@5:0.0415	 hit@10: 0.0780
epoch 23: train_loss = 1.122849, source_hit@10 = 0.0827, source_ndcg@10 = 0.0409, target_hit@10 = 0.0780, target_ndcg@10 = 0.0376

2024-08-03 12:24:32.083373: step 8232/27440 (epoch 24/80), loss = 1.119680 (50.952 sec/epoch), lr: 0.002940
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.045323	 ndcg_5: 0.0355	 ndcg_10: 0.0486	 hit@1:0.015843	 hit@5:0.0554	 hit@10: 0.0966
target: 	 mrr: 0.035876	 ndcg_5: 0.0265	 ndcg_10: 0.0362	 hit@1:0.010031	 hit@5:0.0429	 hit@10: 0.0727
epoch 24: train_loss = 1.119680, source_hit@10 = 0.0966, source_ndcg@10 = 0.0486, target_hit@10 = 0.0727, target_ndcg@10 = 0.0362

2024-08-03 12:25:23.549564: step 8575/27440 (epoch 25/80), loss = 1.116898 (50.717 sec/epoch), lr: 0.002940
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.053511	 ndcg_5: 0.0451	 ndcg_10: 0.0580	 hit@1:0.021863	 hit@5:0.0684	 hit@10: 0.1080
target: 	 mrr: 0.035673	 ndcg_5: 0.0291	 ndcg_10: 0.0369	 hit@1:0.012538	 hit@5:0.0468	 hit@10: 0.0713
source best!
..............................
source: 	 mrr: 0.045275	 ndcg_5: 0.0368	 ndcg_10: 0.0481	 hit@1:0.013290	 hit@5:0.0590	 hit@10: 0.0947
epoch 25: train_loss = 1.116898, source_hit@10 = 0.0947, source_ndcg@10 = 0.0481, target_hit@10 = 0.0713, target_ndcg@10 = 0.0369

2024-08-03 12:26:15.697633: step 8918/27440 (epoch 26/80), loss = 1.117440 (51.014 sec/epoch), lr: 0.002940
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.044693	 ndcg_5: 0.0336	 ndcg_10: 0.0475	 hit@1:0.015843	 hit@5:0.0507	 hit@10: 0.0941
target: 	 mrr: 0.033900	 ndcg_5: 0.0257	 ndcg_10: 0.0352	 hit@1:0.010309	 hit@5:0.0410	 hit@10: 0.0705
epoch 26: train_loss = 1.117440, source_hit@10 = 0.0941, source_ndcg@10 = 0.0475, target_hit@10 = 0.0705, target_ndcg@10 = 0.0352

2024-08-03 12:27:07.130613: step 9261/27440 (epoch 27/80), loss = 1.113335 (50.683 sec/epoch), lr: 0.002793
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.035814	 ndcg_5: 0.0258	 ndcg_10: 0.0358	 hit@1:0.011407	 hit@5:0.0409	 hit@10: 0.0719
target: 	 mrr: 0.038434	 ndcg_5: 0.0292	 ndcg_10: 0.0407	 hit@1:0.013096	 hit@5:0.0463	 hit@10: 0.0822
epoch 27: train_loss = 1.113335, source_hit@10 = 0.0719, source_ndcg@10 = 0.0358, target_hit@10 = 0.0822, target_ndcg@10 = 0.0407

2024-08-03 12:27:58.457524: step 9604/27440 (epoch 28/80), loss = 1.109773 (50.579 sec/epoch), lr: 0.002654
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.038938	 ndcg_5: 0.0284	 ndcg_10: 0.0404	 hit@1:0.012041	 hit@5:0.0456	 hit@10: 0.0830
target: 	 mrr: 0.035184	 ndcg_5: 0.0263	 ndcg_10: 0.0362	 hit@1:0.010031	 hit@5:0.0435	 hit@10: 0.0744
epoch 28: train_loss = 1.109773, source_hit@10 = 0.0830, source_ndcg@10 = 0.0404, target_hit@10 = 0.0744, target_ndcg@10 = 0.0362

2024-08-03 12:28:50.412560: step 9947/27440 (epoch 29/80), loss = 1.107970 (51.212 sec/epoch), lr: 0.002521
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.042642	 ndcg_5: 0.0332	 ndcg_10: 0.0468	 hit@1:0.012991	 hit@5:0.0548	 hit@10: 0.0973
target: 	 mrr: 0.034702	 ndcg_5: 0.0263	 ndcg_10: 0.0373	 hit@1:0.009195	 hit@5:0.0443	 hit@10: 0.0786
epoch 29: train_loss = 1.107970, source_hit@10 = 0.0973, source_ndcg@10 = 0.0468, target_hit@10 = 0.0786, target_ndcg@10 = 0.0373

2024-08-03 12:29:41.974926: step 10290/27440 (epoch 30/80), loss = 1.106429 (50.822 sec/epoch), lr: 0.002521
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.041375	 ndcg_5: 0.0308	 ndcg_10: 0.0449	 hit@1:0.012674	 hit@5:0.0497	 hit@10: 0.0935
target: 	 mrr: 0.032660	 ndcg_5: 0.0260	 ndcg_10: 0.0338	 hit@1:0.011424	 hit@5:0.0404	 hit@10: 0.0646
epoch 30: train_loss = 1.106429, source_hit@10 = 0.0935, source_ndcg@10 = 0.0449, target_hit@10 = 0.0646, target_ndcg@10 = 0.0338

2024-08-03 12:30:33.475522: step 10633/27440 (epoch 31/80), loss = 1.103599 (50.752 sec/epoch), lr: 0.002395
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.045911	 ndcg_5: 0.0385	 ndcg_10: 0.0505	 hit@1:0.013308	 hit@5:0.0631	 hit@10: 0.1004
target: 	 mrr: 0.035712	 ndcg_5: 0.0273	 ndcg_10: 0.0383	 hit@1:0.010867	 hit@5:0.0446	 hit@10: 0.0786
epoch 31: train_loss = 1.103599, source_hit@10 = 0.1004, source_ndcg@10 = 0.0505, target_hit@10 = 0.0786, target_ndcg@10 = 0.0383

2024-08-03 12:31:24.912835: step 10976/27440 (epoch 32/80), loss = 1.101645 (50.675 sec/epoch), lr: 0.002395
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.046298	 ndcg_5: 0.0363	 ndcg_10: 0.0486	 hit@1:0.017744	 hit@5:0.0551	 hit@10: 0.0938
target: 	 mrr: 0.036854	 ndcg_5: 0.0272	 ndcg_10: 0.0388	 hit@1:0.009473	 hit@5:0.0446	 hit@10: 0.0805
epoch 32: train_loss = 1.101645, source_hit@10 = 0.0938, source_ndcg@10 = 0.0486, target_hit@10 = 0.0805, target_ndcg@10 = 0.0388

2024-08-03 12:32:16.587573: step 11319/27440 (epoch 33/80), loss = 1.101403 (50.923 sec/epoch), lr: 0.002395
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.042376	 ndcg_5: 0.0335	 ndcg_10: 0.0445	 hit@1:0.012991	 hit@5:0.0535	 hit@10: 0.0878
target: 	 mrr: 0.037435	 ndcg_5: 0.0276	 ndcg_10: 0.0374	 hit@1:0.013653	 hit@5:0.0421	 hit@10: 0.0724
epoch 33: train_loss = 1.101403, source_hit@10 = 0.0878, source_ndcg@10 = 0.0445, target_hit@10 = 0.0724, target_ndcg@10 = 0.0374

2024-08-03 12:33:08.068776: step 11662/27440 (epoch 34/80), loss = 1.100414 (50.743 sec/epoch), lr: 0.002275
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.048652	 ndcg_5: 0.0413	 ndcg_10: 0.0527	 hit@1:0.017744	 hit@5:0.0643	 hit@10: 0.0995
target: 	 mrr: 0.035260	 ndcg_5: 0.0278	 ndcg_10: 0.0367	 hit@1:0.011702	 hit@5:0.0437	 hit@10: 0.0713
epoch 34: train_loss = 1.100414, source_hit@10 = 0.0995, source_ndcg@10 = 0.0527, target_hit@10 = 0.0713, target_ndcg@10 = 0.0367

2024-08-03 12:33:59.418260: step 12005/27440 (epoch 35/80), loss = 1.097527 (50.607 sec/epoch), lr: 0.002275
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.045627	 ndcg_5: 0.0360	 ndcg_10: 0.0487	 hit@1:0.015843	 hit@5:0.0561	 hit@10: 0.0960
target: 	 mrr: 0.037798	 ndcg_5: 0.0287	 ndcg_10: 0.0386	 hit@1:0.013374	 hit@5:0.0440	 hit@10: 0.0750
epoch 35: train_loss = 1.097527, source_hit@10 = 0.0960, source_ndcg@10 = 0.0487, target_hit@10 = 0.0750, target_ndcg@10 = 0.0386

2024-08-03 12:34:50.417578: step 12348/27440 (epoch 36/80), loss = 1.093730 (50.256 sec/epoch), lr: 0.002161
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.046797	 ndcg_5: 0.0375	 ndcg_10: 0.0490	 hit@1:0.017744	 hit@5:0.0564	 hit@10: 0.0919
target: 	 mrr: 0.039913	 ndcg_5: 0.0295	 ndcg_10: 0.0416	 hit@1:0.014767	 hit@5:0.0443	 hit@10: 0.0825
epoch 36: train_loss = 1.093730, source_hit@10 = 0.0919, source_ndcg@10 = 0.0490, target_hit@10 = 0.0825, target_ndcg@10 = 0.0416

2024-08-03 12:35:41.691836: step 12691/27440 (epoch 37/80), loss = 1.092889 (50.534 sec/epoch), lr: 0.002161
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.042697	 ndcg_5: 0.0349	 ndcg_10: 0.0461	 hit@1:0.010773	 hit@5:0.0586	 hit@10: 0.0938
target: 	 mrr: 0.037024	 ndcg_5: 0.0274	 ndcg_10: 0.0391	 hit@1:0.010588	 hit@5:0.0446	 hit@10: 0.0814
epoch 37: train_loss = 1.092889, source_hit@10 = 0.0938, source_ndcg@10 = 0.0461, target_hit@10 = 0.0814, target_ndcg@10 = 0.0391

2024-08-03 12:36:33.249024: step 13034/27440 (epoch 38/80), loss = 1.091986 (50.822 sec/epoch), lr: 0.002053
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.046608	 ndcg_5: 0.0386	 ndcg_10: 0.0481	 hit@1:0.019645	 hit@5:0.0574	 hit@10: 0.0875
target: 	 mrr: 0.036182	 ndcg_5: 0.0288	 ndcg_10: 0.0394	 hit@1:0.009473	 hit@5:0.0496	 hit@10: 0.0828
epoch 38: train_loss = 1.091986, source_hit@10 = 0.0875, source_ndcg@10 = 0.0481, target_hit@10 = 0.0828, target_ndcg@10 = 0.0394

2024-08-03 12:37:24.757945: step 13377/27440 (epoch 39/80), loss = 1.090348 (50.770 sec/epoch), lr: 0.002053
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.045269	 ndcg_5: 0.0364	 ndcg_10: 0.0478	 hit@1:0.014259	 hit@5:0.0593	 hit@10: 0.0947
target: 	 mrr: 0.036931	 ndcg_5: 0.0285	 ndcg_10: 0.0409	 hit@1:0.008080	 hit@5:0.0510	 hit@10: 0.0894
epoch 39: train_loss = 1.090348, source_hit@10 = 0.0947, source_ndcg@10 = 0.0478, target_hit@10 = 0.0894, target_ndcg@10 = 0.0409

2024-08-03 12:38:15.386663: step 13720/27440 (epoch 40/80), loss = 1.086536 (49.880 sec/epoch), lr: 0.001951
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.045012	 ndcg_5: 0.0370	 ndcg_10: 0.0476	 hit@1:0.015526	 hit@5:0.0608	 hit@10: 0.0938
target: 	 mrr: 0.041432	 ndcg_5: 0.0324	 ndcg_10: 0.0446	 hit@1:0.012260	 hit@5:0.0527	 hit@10: 0.0908
epoch 40: train_loss = 1.086536, source_hit@10 = 0.0938, source_ndcg@10 = 0.0476, target_hit@10 = 0.0908, target_ndcg@10 = 0.0446
shift to transfer learning mode

2024-08-03 12:39:07.886364: step 14063/27440 (epoch 41/80), loss = 1.087319 (51.697 sec/epoch), lr: 0.001951
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.042509	 ndcg_5: 0.0326	 ndcg_10: 0.0434	 hit@1:0.013625	 hit@5:0.0510	 hit@10: 0.0846
target: 	 mrr: 0.033920	 ndcg_5: 0.0264	 ndcg_10: 0.0343	 hit@1:0.012538	 hit@5:0.0401	 hit@10: 0.0641
epoch 41: train_loss = 1.087319, source_hit@10 = 0.0846, source_ndcg@10 = 0.0434, target_hit@10 = 0.0641, target_ndcg@10 = 0.0343

2024-08-03 12:40:00.606713: step 14406/27440 (epoch 42/80), loss = 1.082566 (51.951 sec/epoch), lr: 0.001853
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.046193	 ndcg_5: 0.0367	 ndcg_10: 0.0502	 hit@1:0.014575	 hit@5:0.0599	 hit@10: 0.1014
target: 	 mrr: 0.039909	 ndcg_5: 0.0321	 ndcg_10: 0.0418	 hit@1:0.014210	 hit@5:0.0504	 hit@10: 0.0805
epoch 42: train_loss = 1.082566, source_hit@10 = 0.1014, source_ndcg@10 = 0.0502, target_hit@10 = 0.0805, target_ndcg@10 = 0.0418

2024-08-03 12:40:53.395082: step 14749/27440 (epoch 43/80), loss = 1.084248 (52.015 sec/epoch), lr: 0.001853
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.043011	 ndcg_5: 0.0342	 ndcg_10: 0.0470	 hit@1:0.013942	 hit@5:0.0545	 hit@10: 0.0944
target: 	 mrr: 0.040437	 ndcg_5: 0.0311	 ndcg_10: 0.0448	 hit@1:0.011981	 hit@5:0.0515	 hit@10: 0.0942
epoch 43: train_loss = 1.084248, source_hit@10 = 0.0944, source_ndcg@10 = 0.0470, target_hit@10 = 0.0942, target_ndcg@10 = 0.0448

2024-08-03 12:41:45.664631: step 15092/27440 (epoch 44/80), loss = 1.081191 (51.532 sec/epoch), lr: 0.001761
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.045549	 ndcg_5: 0.0358	 ndcg_10: 0.0498	 hit@1:0.015209	 hit@5:0.0577	 hit@10: 0.1011
target: 	 mrr: 0.034127	 ndcg_5: 0.0252	 ndcg_10: 0.0345	 hit@1:0.008638	 hit@5:0.0421	 hit@10: 0.0711
epoch 44: train_loss = 1.081191, source_hit@10 = 0.1011, source_ndcg@10 = 0.0498, target_hit@10 = 0.0711, target_ndcg@10 = 0.0345

2024-08-03 12:42:37.671920: step 15435/27440 (epoch 45/80), loss = 1.076667 (51.269 sec/epoch), lr: 0.001672
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.048700	 ndcg_5: 0.0390	 ndcg_10: 0.0532	 hit@1:0.016793	 hit@5:0.0618	 hit@10: 0.1058
target: 	 mrr: 0.041826	 ndcg_5: 0.0334	 ndcg_10: 0.0445	 hit@1:0.013374	 hit@5:0.0529	 hit@10: 0.0872
epoch 45: train_loss = 1.076667, source_hit@10 = 0.1058, source_ndcg@10 = 0.0532, target_hit@10 = 0.0872, target_ndcg@10 = 0.0445

2024-08-03 12:43:30.429153: step 15778/27440 (epoch 46/80), loss = 1.076280 (52.009 sec/epoch), lr: 0.001672
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.050635	 ndcg_5: 0.0424	 ndcg_10: 0.0546	 hit@1:0.018061	 hit@5:0.0662	 hit@10: 0.1042
target: 	 mrr: 0.039012	 ndcg_5: 0.0304	 ndcg_10: 0.0417	 hit@1:0.011981	 hit@5:0.0490	 hit@10: 0.0839
epoch 46: train_loss = 1.076280, source_hit@10 = 0.1042, source_ndcg@10 = 0.0546, target_hit@10 = 0.0839, target_ndcg@10 = 0.0417

2024-08-03 12:44:23.164178: step 16121/27440 (epoch 47/80), loss = 1.073921 (51.999 sec/epoch), lr: 0.001589
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.049657	 ndcg_5: 0.0419	 ndcg_10: 0.0541	 hit@1:0.017427	 hit@5:0.0669	 hit@10: 0.1046
target: 	 mrr: 0.038798	 ndcg_5: 0.0304	 ndcg_10: 0.0410	 hit@1:0.011145	 hit@5:0.0493	 hit@10: 0.0819
epoch 47: train_loss = 1.073921, source_hit@10 = 0.1046, source_ndcg@10 = 0.0541, target_hit@10 = 0.0819, target_ndcg@10 = 0.0410

2024-08-03 12:45:16.301111: step 16464/27440 (epoch 48/80), loss = 1.070918 (52.375 sec/epoch), lr: 0.001509
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.047618	 ndcg_5: 0.0380	 ndcg_10: 0.0508	 hit@1:0.015843	 hit@5:0.0608	 hit@10: 0.1004
target: 	 mrr: 0.039345	 ndcg_5: 0.0311	 ndcg_10: 0.0431	 hit@1:0.011145	 hit@5:0.0515	 hit@10: 0.0889
epoch 48: train_loss = 1.070918, source_hit@10 = 0.1004, source_ndcg@10 = 0.0508, target_hit@10 = 0.0889, target_ndcg@10 = 0.0431

2024-08-03 12:46:08.635460: step 16807/27440 (epoch 49/80), loss = 1.067318 (51.571 sec/epoch), lr: 0.001434
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.052650	 ndcg_5: 0.0446	 ndcg_10: 0.0584	 hit@1:0.020913	 hit@5:0.0681	 hit@10: 0.1115
target: 	 mrr: 0.038952	 ndcg_5: 0.0312	 ndcg_10: 0.0415	 hit@1:0.011145	 hit@5:0.0518	 hit@10: 0.0839
epoch 49: train_loss = 1.067318, source_hit@10 = 0.1115, source_ndcg@10 = 0.0584, target_hit@10 = 0.0839, target_ndcg@10 = 0.0415

2024-08-03 12:47:01.826645: step 17150/27440 (epoch 50/80), loss = 1.064233 (52.454 sec/epoch), lr: 0.001434
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.051933	 ndcg_5: 0.0434	 ndcg_10: 0.0563	 hit@1:0.019011	 hit@5:0.0684	 hit@10: 0.1080
target: 	 mrr: 0.040967	 ndcg_5: 0.0325	 ndcg_10: 0.0436	 hit@1:0.011702	 hit@5:0.0532	 hit@10: 0.0878
epoch 50: train_loss = 1.064233, source_hit@10 = 0.1080, source_ndcg@10 = 0.0563, target_hit@10 = 0.0878, target_ndcg@10 = 0.0436

2024-08-03 12:47:54.588479: step 17493/27440 (epoch 51/80), loss = 1.065982 (52.019 sec/epoch), lr: 0.001434
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.037946	 ndcg_5: 0.0274	 ndcg_10: 0.0383	 hit@1:0.013308	 hit@5:0.0418	 hit@10: 0.0757
target: 	 mrr: 0.040265	 ndcg_5: 0.0314	 ndcg_10: 0.0433	 hit@1:0.009473	 hit@5:0.0527	 hit@10: 0.0897
epoch 51: train_loss = 1.065982, source_hit@10 = 0.0757, source_ndcg@10 = 0.0383, target_hit@10 = 0.0897, target_ndcg@10 = 0.0433
early termination of training
