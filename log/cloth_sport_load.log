nohup: ignoring input
using gpu:0 to train the model
using gpu:0 to train the model
cuda:0
Namespace(A_split=False, JK='sum', a_fold=100, aggregate=False, batch_size=512, beta=1.5, conv_layers=4, cuda=True, decay_epoch=5, device=device(type='cuda', index=0), device_id='0', domains='cloth_sport', dropout=0.2, epoch=200, feature_dim=192, hidden_dim=192, keep_prob=0.6, lambda_constra=0.15, lambda_critic=0.35, lambda_ease=50, leakey=0.01, load=True, log='logs.txt', log_epoch=5, lr=0.0005, lr_decay=0.95, lr_transfer=0.0005, mask_rate=0.1, maxlen=10, min_epoch=50, mode='train', model_file='checkpoint_epoch_40.pt', model_name='cs', num_latent_factors=8, num_negative=10, optim='adam', patience=50, proj_layers=1, projection=1, residual=1, save=True, save_dir='./saved_models', seed=32, sim_threshold=0.9, static_sample=False, tau=0.4, test_sample_number=999, transfer_epoch=40, user_batch_size=256, weight_decay=0.0002)
number_user 41829
number_item 17943
732772292
49873
/home/hourun/invariantCDR_v2/invariantCDR/utils/GraphMaker.py:47: RuntimeWarning: divide by zero encountered in power
  r_inv = np.power(rowsum, -1).flatten()
real graph loaded!
Original edge number: 187880; Augmentation edge number: 192213; adding 4333 edges
augmentation graph loaded!
number_user 27328
number_item 12655
333408046
80379
real graph loaded!
Original edge number: 163291; Augmentation edge number: 175271; adding 11980 edges
augmentation graph loaded!
graph loaded!
Loading data from cloth_sport with batch size 512...
unseen test: 0
test length: 3156
unseen test: 0
test length: 3085
unseen test: 0
test length: 3589
unseen test: 0
test length: 3546
source_user_num 41829
target_user_num 27328
source_item_num 17943
target_item_num 12655
shared users id: 7857
test users 990, 982
unseen test: 0
dev length: 1000
unseen test: 0
dev length: 1000
source train data : 187880, target train data: 163291, source test data : 3085, target test data : 3546, source dev data : 1000, target dev data : 1000
Loading model from ./saved_models/cs/checkpoint_epoch_40.pt
Traceback (most recent call last):
  File "main.py", line 63, in <module>
    results = runner.train()
  File "/home/hourun/invariantCDR_v2/invariantCDR/runner.py", line 268, in train
    loss = self.reconstruct_graph(batch, self.args.source_UV, self.args.source_VU, self.args.target_UV, self.args.target_VU,
  File "/home/hourun/invariantCDR_v2/invariantCDR/runner.py", line 141, in reconstruct_graph
    self.aug_source_user, self.aug_source_item, self.aug_target_user, self.aug_target_item = self.recmodel(aug_source_UV, aug_source_VU, aug_target_UV, aug_target_VU)
  File "/home/hourun/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/hourun/invariantCDR_v2/invariantCDR/model/invariantCDR.py", line 235, in forward
    target_learn_user, target_learn_item = self.target_disenEncoder(target_user, target_item, target_UV, target_VU)
  File "/home/hourun/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/hourun/invariantCDR_v2/invariantCDR/model/Encoder.py", line 182, in forward
    learn_user, learn_item = self._disen_conv(learn_user, learn_item, UV_adj, VU_adj)
  File "/home/hourun/invariantCDR_v2/invariantCDR/model/Encoder.py", line 151, in _disen_conv
    learn_user, learn_item = self.disen_convolution_list[i * self.proj_layers + j](learn_user, learn_item, UV_adj, VU_adj)
  File "/home/hourun/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/hourun/invariantCDR_v2/invariantCDR/model/Encoder.py", line 296, in forward
    User_ho = self.gc3(User_ho, UV_adj)
  File "/home/hourun/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/hourun/invariantCDR_v2/invariantCDR/model/GCN.py", line 31, in forward
    x = self.leakyrelu(self.gc1(x, adj))
  File "/home/hourun/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/hourun/invariantCDR_v2/invariantCDR/model/GCN.py", line 99, in forward
    output = torch.spmm(adj, support)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 22.00 MiB (GPU 0; 23.65 GiB total capacity; 22.05 GiB already allocated; 10.81 MiB free; 22.27 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
