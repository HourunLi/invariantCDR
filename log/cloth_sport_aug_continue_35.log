nohup: ignoring input
using gpu:1 to train the model
using gpu:1 to train the model
cuda:1
Namespace(A_split=False, JK='sum', a_fold=100, aggregate=False, batch_size=1024, beta=1.5, conv_layers=3, cuda=True, decay_epoch=5, device=device(type='cuda', index=1), device_id='1', domains='cloth_sport', dropout=0.2, epoch=70, feature_dim=126, hidden_dim=126, keep_prob=0.6, lambda_constra=0.15, lambda_critic=0.25, lambda_ease=50, leakey=0.01, load=True, log='logs.txt', log_epoch=1, lr=0.0005, lr_decay=0.95, lr_transfer=0.0005, mask_rate=0.1, min_epoch=50, mode='train', model_file='checkpoint_epoch_35.pt', model_name='cs', num_latent_factors=3, num_negative=10, optim='adam', patience=50, proj_layers=1, projection=1, residual=1, save=True, save_dir='./saved_models', seed=32, sim_threshold=0.9, tau=0.6, test_sample_number=999, transfer_epoch=35, user_batch_size=256, weight_decay=0.0002)
number_user 41829
number_item 17943
/home/hourun/invariantCDR_v2/invariantCDR/utils/GraphMaker.py:47: RuntimeWarning: divide by zero encountered in power
  r_inv = np.power(rowsum, -1).flatten()
real graph loaded!
augmented graph loaded!
number_user 27328
number_item 12655
real graph loaded!
augmented graph loaded!
graph loaded!
Loading data from cloth_sport with batch size 1024...
unseen test: 0
test length: 3156
unseen test: 0
test length: 3085
unseen test: 0
test length: 3589
unseen test: 0
test length: 3546
source_user_num 41829
target_user_num 27328
source_item_num 17943
target_item_num 12655
shared users id: 7857
test users 990, 982
unseen test: 0
dev length: 1000
unseen test: 0
dev length: 1000
source train data : 187880, target train data: 163291, source test data : 3085, target test data : 3546, source dev data : 1000, target dev data : 1000
Loading model from ./saved_models/cs/checkpoint_epoch_35.pt
2024-07-11 00:53:03.756368: step 343/24010 (epoch 35/70), loss = 0.392055 (100.255 sec/epoch), lr: 0.000500
Evaluating on dev set...
....................
source: 	 mrr: 0.122087	 ndcg_5: 0.1128	 ndcg_10: 0.1474	 hit@1:0.044000	 hit@5:0.1810	 hit@10: 0.2890
target: 	 mrr: 0.046943	 ndcg_5: 0.0360	 ndcg_10: 0.0526	 hit@1:0.013000	 hit@5:0.0600	 hit@10: 0.1120
new best model saved.

2024-07-11 00:54:43.808445: step 686/24010 (epoch 36/70), loss = 0.683672 (99.423 sec/epoch), lr: 0.000500
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.042758	 ndcg_5: 0.0345	 ndcg_10: 0.0439	 hit@1:0.016477	 hit@5:0.0523	 hit@10: 0.0817
target: 	 mrr: 0.040881	 ndcg_5: 0.0336	 ndcg_10: 0.0432	 hit@1:0.013653	 hit@5:0.0527	 hit@10: 0.0819
epoch 36: train_loss = 0.683672, source_hit@10 = 0.0817, source_ndcg@10 = 0.0439, target_hit@10 = 0.0819, target_ndcg@10 = 0.0432

2024-07-11 00:56:24.281786: step 1029/24010 (epoch 37/70), loss = 0.612972 (99.542 sec/epoch), lr: 0.000475
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.047342	 ndcg_5: 0.0406	 ndcg_10: 0.0492	 hit@1:0.020596	 hit@5:0.0602	 hit@10: 0.0871
target: 	 mrr: 0.035383	 ndcg_5: 0.0288	 ndcg_10: 0.0361	 hit@1:0.012538	 hit@5:0.0457	 hit@10: 0.0688
epoch 37: train_loss = 0.612972, source_hit@10 = 0.0871, source_ndcg@10 = 0.0492, target_hit@10 = 0.0688, target_ndcg@10 = 0.0361

2024-07-11 00:58:04.748072: step 1372/24010 (epoch 38/70), loss = 0.582640 (99.513 sec/epoch), lr: 0.000451
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.042953	 ndcg_5: 0.0356	 ndcg_10: 0.0435	 hit@1:0.017110	 hit@5:0.0542	 hit@10: 0.0789
target: 	 mrr: 0.039052	 ndcg_5: 0.0315	 ndcg_10: 0.0419	 hit@1:0.012817	 hit@5:0.0502	 hit@10: 0.0828
epoch 38: train_loss = 0.582640, source_hit@10 = 0.0789, source_ndcg@10 = 0.0435, target_hit@10 = 0.0828, target_ndcg@10 = 0.0419

2024-07-11 00:59:45.096468: step 1715/24010 (epoch 39/70), loss = 0.561436 (99.415 sec/epoch), lr: 0.000429
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.031553	 ndcg_5: 0.0218	 ndcg_10: 0.0308	 hit@1:0.009823	 hit@5:0.0339	 hit@10: 0.0618
target: 	 mrr: 0.041230	 ndcg_5: 0.0334	 ndcg_10: 0.0438	 hit@1:0.016996	 hit@5:0.0502	 hit@10: 0.0828
epoch 39: train_loss = 0.561436, source_hit@10 = 0.0618, source_ndcg@10 = 0.0308, target_hit@10 = 0.0828, target_ndcg@10 = 0.0438

