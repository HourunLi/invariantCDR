nohup: ignoring input
using gpu:1 to train the model
using gpu:1 to train the model
cuda:1
Namespace(A_split=False, JK='sum', a_fold=100, aggregate=False, batch_size=1024, beta=1.5, conv_layers=3, cuda=True, decay_epoch=5, device=device(type='cuda', index=1), device_id='1', domains='cloth_sport', dropout=0.2, epoch=200, feature_dim=126, hidden_dim=126, keep_prob=0.6, lambda_constra=0.15, lambda_critic=0.35, lambda_ease=50, leakey=0.01, load=True, log='logs.txt', log_epoch=1, lr=0.0005, lr_decay=0.95, lr_transfer=0.0005, mask_rate=0.1, min_epoch=50, mode='train', model_file='checkpoint_epoch_25.pt', model_name='cs', num_latent_factors=3, num_negative=10, optim='adam', patience=50, proj_layers=1, projection=1, residual=1, save=True, save_dir='./saved_models', seed=32, sim_threshold=0.9, tau=0.4, test_sample_number=999, transfer_epoch=25, user_batch_size=256, weight_decay=0.0002)
number_user 41829
number_item 17943
732772292
49873
/home/hourun/invariantCDR_v2/invariantCDR/utils/GraphMaker.py:46: RuntimeWarning: divide by zero encountered in power
  r_inv = np.power(rowsum, -1).flatten()
real graph loaded!
Original edge number: 187880; Augmentation edge number: 192213; adding 4333 edges
augmentation graph loaded!
number_user 27328
number_item 12655
333408046
80379
real graph loaded!
Original edge number: 163291; Augmentation edge number: 175271; adding 11980 edges
augmentation graph loaded!
graph loaded!
Loading data from cloth_sport with batch size 1024...
unseen test: 0
test length: 3156
unseen test: 0
test length: 3085
unseen test: 0
test length: 3589
unseen test: 0
test length: 3546
source_user_num 41829
target_user_num 27328
source_item_num 17943
target_item_num 12655
shared users id: 7857
test users 990, 982
unseen test: 0
dev length: 1000
unseen test: 0
dev length: 1000
source train data : 187880, target train data: 163291, source test data : 3085, target test data : 3546, source dev data : 1000, target dev data : 1000
Loading model from ./saved_models/cs/checkpoint_epoch_25.pt
2024-07-04 19:50:42.192407: step 343/68600 (epoch 25/200), loss = 1.495154 (200.040 sec/epoch), lr: 0.000500
Evaluating on dev set...
....................
source: 	 mrr: 0.106608	 ndcg_5: 0.0894	 ndcg_10: 0.1196	 hit@1:0.043000	 hit@5:0.1310	 hit@10: 0.2250
target: 	 mrr: 0.146758	 ndcg_5: 0.1351	 ndcg_10: 0.1698	 hit@1:0.063000	 hit@5:0.2050	 hit@10: 0.3120
new best model saved.

2024-07-04 19:54:01.626450: step 686/68600 (epoch 26/200), loss = 1.426506 (198.807 sec/epoch), lr: 0.000500
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.052070	 ndcg_5: 0.0430	 ndcg_10: 0.0578	 hit@1:0.018378	 hit@5:0.0684	 hit@10: 0.1144
target: 	 mrr: 0.045175	 ndcg_5: 0.0365	 ndcg_10: 0.0483	 hit@1:0.016439	 hit@5:0.0557	 hit@10: 0.0928
epoch 26: train_loss = 1.426506, source_hit@10 = 0.1144, source_ndcg@10 = 0.0578, target_hit@10 = 0.0928, target_ndcg@10 = 0.0483

2024-07-04 19:57:21.399650: step 1029/68600 (epoch 27/200), loss = 1.385073 (198.859 sec/epoch), lr: 0.000475
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.049577	 ndcg_5: 0.0408	 ndcg_10: 0.0539	 hit@1:0.018378	 hit@5:0.0650	 hit@10: 0.1055
target: 	 mrr: 0.049348	 ndcg_5: 0.0404	 ndcg_10: 0.0554	 hit@1:0.016718	 hit@5:0.0638	 hit@10: 0.1106
epoch 27: train_loss = 1.385073, source_hit@10 = 0.1055, source_ndcg@10 = 0.0539, target_hit@10 = 0.1106, target_ndcg@10 = 0.0554

2024-07-04 20:00:41.342224: step 1372/68600 (epoch 28/200), loss = 1.361603 (199.031 sec/epoch), lr: 0.000475
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.043323	 ndcg_5: 0.0334	 ndcg_10: 0.0472	 hit@1:0.014259	 hit@5:0.0529	 hit@10: 0.0960
target: 	 mrr: 0.049218	 ndcg_5: 0.0397	 ndcg_10: 0.0528	 hit@1:0.019783	 hit@5:0.0591	 hit@10: 0.0997
epoch 28: train_loss = 1.361603, source_hit@10 = 0.0960, source_ndcg@10 = 0.0472, target_hit@10 = 0.0997, target_ndcg@10 = 0.0528

2024-07-04 20:04:01.278696: step 1715/68600 (epoch 29/200), loss = 1.335134 (199.025 sec/epoch), lr: 0.000451
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.033867	 ndcg_5: 0.0266	 ndcg_10: 0.0350	 hit@1:0.012674	 hit@5:0.0399	 hit@10: 0.0662
target: 	 mrr: 0.046172	 ndcg_5: 0.0373	 ndcg_10: 0.0484	 hit@1:0.018668	 hit@5:0.0549	 hit@10: 0.0894
epoch 29: train_loss = 1.335134, source_hit@10 = 0.0662, source_ndcg@10 = 0.0350, target_hit@10 = 0.0894, target_ndcg@10 = 0.0484

2024-07-04 20:07:21.157149: step 2058/68600 (epoch 30/200), loss = 1.316522 (198.962 sec/epoch), lr: 0.000429
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.051252	 ndcg_5: 0.0425	 ndcg_10: 0.0551	 hit@1:0.019011	 hit@5:0.0662	 hit@10: 0.1061
target: 	 mrr: 0.044316	 ndcg_5: 0.0368	 ndcg_10: 0.0482	 hit@1:0.014767	 hit@5:0.0593	 hit@10: 0.0953
epoch 30: train_loss = 1.316522, source_hit@10 = 0.1061, source_ndcg@10 = 0.0551, target_hit@10 = 0.0953, target_ndcg@10 = 0.0482

2024-07-04 20:10:41.212542: step 2401/68600 (epoch 31/200), loss = 1.298795 (199.139 sec/epoch), lr: 0.000429
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.039729	 ndcg_5: 0.0300	 ndcg_10: 0.0413	 hit@1:0.013942	 hit@5:0.0450	 hit@10: 0.0802
target: 	 mrr: 0.041178	 ndcg_5: 0.0330	 ndcg_10: 0.0422	 hit@1:0.016996	 hit@5:0.0485	 hit@10: 0.0772
epoch 31: train_loss = 1.298795, source_hit@10 = 0.0802, source_ndcg@10 = 0.0413, target_hit@10 = 0.0772, target_ndcg@10 = 0.0422

2024-07-04 20:14:01.079075: step 2744/68600 (epoch 32/200), loss = 1.286315 (198.941 sec/epoch), lr: 0.000407
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.059307	 ndcg_5: 0.0499	 ndcg_10: 0.0653	 hit@1:0.026616	 hit@5:0.0741	 hit@10: 0.1223
target: 	 mrr: 0.041712	 ndcg_5: 0.0321	 ndcg_10: 0.0447	 hit@1:0.013374	 hit@5:0.0510	 hit@10: 0.0900
epoch 32: train_loss = 1.286315, source_hit@10 = 0.1223, source_ndcg@10 = 0.0653, target_hit@10 = 0.0900, target_ndcg@10 = 0.0447

2024-07-04 20:17:20.937293: step 3087/68600 (epoch 33/200), loss = 1.275455 (198.941 sec/epoch), lr: 0.000407
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.048980	 ndcg_5: 0.0396	 ndcg_10: 0.0526	 hit@1:0.018061	 hit@5:0.0612	 hit@10: 0.1017
target: 	 mrr: 0.048099	 ndcg_5: 0.0399	 ndcg_10: 0.0511	 hit@1:0.018947	 hit@5:0.0610	 hit@10: 0.0961
epoch 33: train_loss = 1.275455, source_hit@10 = 0.1017, source_ndcg@10 = 0.0526, target_hit@10 = 0.0961, target_ndcg@10 = 0.0511

2024-07-04 20:20:40.648685: step 3430/68600 (epoch 34/200), loss = 1.262471 (198.796 sec/epoch), lr: 0.000387
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.042697	 ndcg_5: 0.0334	 ndcg_10: 0.0436	 hit@1:0.016477	 hit@5:0.0507	 hit@10: 0.0827
target: 	 mrr: 0.044426	 ndcg_5: 0.0371	 ndcg_10: 0.0461	 hit@1:0.015603	 hit@5:0.0588	 hit@10: 0.0869
epoch 34: train_loss = 1.262471, source_hit@10 = 0.0827, source_ndcg@10 = 0.0436, target_hit@10 = 0.0869, target_ndcg@10 = 0.0461

2024-07-04 20:24:00.329806: step 3773/68600 (epoch 35/200), loss = 1.251361 (198.765 sec/epoch), lr: 0.000368
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.038927	 ndcg_5: 0.0304	 ndcg_10: 0.0426	 hit@1:0.011090	 hit@5:0.0504	 hit@10: 0.0884
target: 	 mrr: 0.044642	 ndcg_5: 0.0353	 ndcg_10: 0.0460	 hit@1:0.016160	 hit@5:0.0543	 hit@10: 0.0875
epoch 35: train_loss = 1.251361, source_hit@10 = 0.0884, source_ndcg@10 = 0.0426, target_hit@10 = 0.0875, target_ndcg@10 = 0.0460

2024-07-04 20:27:20.120730: step 4116/68600 (epoch 36/200), loss = 1.240579 (198.886 sec/epoch), lr: 0.000349
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.041816	 ndcg_5: 0.0312	 ndcg_10: 0.0432	 hit@1:0.014892	 hit@5:0.0469	 hit@10: 0.0843
target: 	 mrr: 0.045565	 ndcg_5: 0.0374	 ndcg_10: 0.0498	 hit@1:0.014767	 hit@5:0.0596	 hit@10: 0.0981
epoch 36: train_loss = 1.240579, source_hit@10 = 0.0843, source_ndcg@10 = 0.0432, target_hit@10 = 0.0981, target_ndcg@10 = 0.0498

2024-07-04 20:30:39.894458: step 4459/68600 (epoch 37/200), loss = 1.232552 (198.865 sec/epoch), lr: 0.000349
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.034197	 ndcg_5: 0.0242	 ndcg_10: 0.0357	 hit@1:0.008238	 hit@5:0.0406	 hit@10: 0.0760
target: 	 mrr: 0.047776	 ndcg_5: 0.0380	 ndcg_10: 0.0512	 hit@1:0.016996	 hit@5:0.0588	 hit@10: 0.0997
epoch 37: train_loss = 1.232552, source_hit@10 = 0.0760, source_ndcg@10 = 0.0357, target_hit@10 = 0.0997, target_ndcg@10 = 0.0512

2024-07-04 20:33:59.655952: step 4802/68600 (epoch 38/200), loss = 1.222778 (198.852 sec/epoch), lr: 0.000332
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.037745	 ndcg_5: 0.0272	 ndcg_10: 0.0378	 hit@1:0.011724	 hit@5:0.0431	 hit@10: 0.0760
target: 	 mrr: 0.045935	 ndcg_5: 0.0382	 ndcg_10: 0.0499	 hit@1:0.015325	 hit@5:0.0607	 hit@10: 0.0972
epoch 38: train_loss = 1.222778, source_hit@10 = 0.0760, source_ndcg@10 = 0.0378, target_hit@10 = 0.0972, target_ndcg@10 = 0.0499

2024-07-04 20:37:19.367425: step 5145/68600 (epoch 39/200), loss = 1.221214 (198.796 sec/epoch), lr: 0.000332
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.045478	 ndcg_5: 0.0361	 ndcg_10: 0.0480	 hit@1:0.015209	 hit@5:0.0574	 hit@10: 0.0938
target: 	 mrr: 0.045279	 ndcg_5: 0.0373	 ndcg_10: 0.0489	 hit@1:0.015046	 hit@5:0.0599	 hit@10: 0.0958
epoch 39: train_loss = 1.221214, source_hit@10 = 0.0938, source_ndcg@10 = 0.0480, target_hit@10 = 0.0958, target_ndcg@10 = 0.0489

2024-07-04 20:40:39.138681: step 5488/68600 (epoch 40/200), loss = 1.215862 (198.855 sec/epoch), lr: 0.000332
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.026621	 ndcg_5: 0.0160	 ndcg_10: 0.0256	 hit@1:0.006337	 hit@5:0.0266	 hit@10: 0.0564
target: 	 mrr: 0.041170	 ndcg_5: 0.0335	 ndcg_10: 0.0435	 hit@1:0.013374	 hit@5:0.0541	 hit@10: 0.0853
epoch 40: train_loss = 1.215862, source_hit@10 = 0.0564, source_ndcg@10 = 0.0256, target_hit@10 = 0.0853, target_ndcg@10 = 0.0435

2024-07-04 20:43:58.851277: step 5831/68600 (epoch 41/200), loss = 1.206208 (198.798 sec/epoch), lr: 0.000315
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.026106	 ndcg_5: 0.0178	 ndcg_10: 0.0244	 hit@1:0.005387	 hit@5:0.0311	 hit@10: 0.0516
target: 	 mrr: 0.044825	 ndcg_5: 0.0361	 ndcg_10: 0.0466	 hit@1:0.016718	 hit@5:0.0552	 hit@10: 0.0878
epoch 41: train_loss = 1.206208, source_hit@10 = 0.0516, source_ndcg@10 = 0.0244, target_hit@10 = 0.0878, target_ndcg@10 = 0.0466

2024-07-04 20:47:18.546084: step 6174/68600 (epoch 42/200), loss = 1.202783 (198.780 sec/epoch), lr: 0.000315
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.024019	 ndcg_5: 0.0157	 ndcg_10: 0.0231	 hit@1:0.004753	 hit@5:0.0269	 hit@10: 0.0501
target: 	 mrr: 0.041467	 ndcg_5: 0.0330	 ndcg_10: 0.0436	 hit@1:0.014210	 hit@5:0.0518	 hit@10: 0.0850
epoch 42: train_loss = 1.202783, source_hit@10 = 0.0501, source_ndcg@10 = 0.0231, target_hit@10 = 0.0850, target_ndcg@10 = 0.0436

2024-07-04 20:50:38.216781: step 6517/68600 (epoch 43/200), loss = 1.197362 (198.761 sec/epoch), lr: 0.000299
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.017432	 ndcg_5: 0.0096	 ndcg_10: 0.0144	 hit@1:0.004436	 hit@5:0.0155	 hit@10: 0.0304
target: 	 mrr: 0.041759	 ndcg_5: 0.0322	 ndcg_10: 0.0431	 hit@1:0.015325	 hit@5:0.0493	 hit@10: 0.0833
epoch 43: train_loss = 1.197362, source_hit@10 = 0.0304, source_ndcg@10 = 0.0144, target_hit@10 = 0.0833, target_ndcg@10 = 0.0431

2024-07-04 20:53:57.978549: step 6860/68600 (epoch 44/200), loss = 1.190373 (198.851 sec/epoch), lr: 0.000284
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.019122	 ndcg_5: 0.0108	 ndcg_10: 0.0164	 hit@1:0.002535	 hit@5:0.0187	 hit@10: 0.0361
target: 	 mrr: 0.046208	 ndcg_5: 0.0374	 ndcg_10: 0.0490	 hit@1:0.016996	 hit@5:0.0571	 hit@10: 0.0936
epoch 44: train_loss = 1.190373, source_hit@10 = 0.0361, source_ndcg@10 = 0.0164, target_hit@10 = 0.0936, target_ndcg@10 = 0.0490

2024-07-04 20:57:17.679013: step 7203/68600 (epoch 45/200), loss = 1.185284 (198.791 sec/epoch), lr: 0.000284
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.019044	 ndcg_5: 0.0109	 ndcg_10: 0.0167	 hit@1:0.002218	 hit@5:0.0203	 hit@10: 0.0383
target: 	 mrr: 0.045058	 ndcg_5: 0.0352	 ndcg_10: 0.0458	 hit@1:0.020061	 hit@5:0.0510	 hit@10: 0.0844
epoch 45: train_loss = 1.185284, source_hit@10 = 0.0383, source_ndcg@10 = 0.0167, target_hit@10 = 0.0844, target_ndcg@10 = 0.0458

2024-07-04 21:00:37.408981: step 7546/68600 (epoch 46/200), loss = 1.179342 (198.815 sec/epoch), lr: 0.000270
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.045280	 ndcg_5: 0.0357	 ndcg_10: 0.0470	 hit@1:0.015209	 hit@5:0.0542	 hit@10: 0.0894
target: 	 mrr: 0.044002	 ndcg_5: 0.0352	 ndcg_10: 0.0451	 hit@1:0.017554	 hit@5:0.0529	 hit@10: 0.0839
epoch 46: train_loss = 1.179342, source_hit@10 = 0.0894, source_ndcg@10 = 0.0470, target_hit@10 = 0.0839, target_ndcg@10 = 0.0451

2024-07-04 21:03:57.168456: step 7889/68600 (epoch 47/200), loss = 1.174572 (198.848 sec/epoch), lr: 0.000270
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.046133	 ndcg_5: 0.0385	 ndcg_10: 0.0480	 hit@1:0.017427	 hit@5:0.0599	 hit@10: 0.0897
target: 	 mrr: 0.045787	 ndcg_5: 0.0361	 ndcg_10: 0.0475	 hit@1:0.019225	 hit@5:0.0529	 hit@10: 0.0886
epoch 47: train_loss = 1.174572, source_hit@10 = 0.0897, source_ndcg@10 = 0.0480, target_hit@10 = 0.0886, target_ndcg@10 = 0.0475

2024-07-04 21:07:16.890006: step 8232/68600 (epoch 48/200), loss = 1.170388 (198.811 sec/epoch), lr: 0.000270
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.040146	 ndcg_5: 0.0306	 ndcg_10: 0.0392	 hit@1:0.013942	 hit@5:0.0472	 hit@10: 0.0745
target: 	 mrr: 0.040011	 ndcg_5: 0.0312	 ndcg_10: 0.0416	 hit@1:0.014767	 hit@5:0.0482	 hit@10: 0.0808
epoch 48: train_loss = 1.170388, source_hit@10 = 0.0745, source_ndcg@10 = 0.0392, target_hit@10 = 0.0808, target_ndcg@10 = 0.0416

2024-07-04 21:10:36.566438: step 8575/68600 (epoch 49/200), loss = 1.166947 (198.764 sec/epoch), lr: 0.000257
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.045817	 ndcg_5: 0.0379	 ndcg_10: 0.0474	 hit@1:0.016793	 hit@5:0.0586	 hit@10: 0.0884
target: 	 mrr: 0.044537	 ndcg_5: 0.0349	 ndcg_10: 0.0469	 hit@1:0.017832	 hit@5:0.0524	 hit@10: 0.0894
epoch 49: train_loss = 1.166947, source_hit@10 = 0.0884, source_ndcg@10 = 0.0474, target_hit@10 = 0.0894, target_ndcg@10 = 0.0469

2024-07-04 21:13:56.361733: step 8918/68600 (epoch 50/200), loss = 1.163112 (198.882 sec/epoch), lr: 0.000257
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.035980	 ndcg_5: 0.0267	 ndcg_10: 0.0356	 hit@1:0.012357	 hit@5:0.0415	 hit@10: 0.0694
target: 	 mrr: 0.045620	 ndcg_5: 0.0367	 ndcg_10: 0.0470	 hit@1:0.018390	 hit@5:0.0549	 hit@10: 0.0872
epoch 50: train_loss = 1.163112, source_hit@10 = 0.0694, source_ndcg@10 = 0.0356, target_hit@10 = 0.0872, target_ndcg@10 = 0.0470

2024-07-04 21:17:16.154233: step 9261/68600 (epoch 51/200), loss = 1.156919 (198.881 sec/epoch), lr: 0.000244
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.041420	 ndcg_5: 0.0319	 ndcg_10: 0.0431	 hit@1:0.012991	 hit@5:0.0507	 hit@10: 0.0856
target: 	 mrr: 0.043708	 ndcg_5: 0.0349	 ndcg_10: 0.0441	 hit@1:0.017275	 hit@5:0.0518	 hit@10: 0.0805
epoch 51: train_loss = 1.156919, source_hit@10 = 0.0856, source_ndcg@10 = 0.0431, target_hit@10 = 0.0805, target_ndcg@10 = 0.0441

2024-07-04 21:20:35.994674: step 9604/68600 (epoch 52/200), loss = 1.154761 (198.933 sec/epoch), lr: 0.000244
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.036979	 ndcg_5: 0.0267	 ndcg_10: 0.0350	 hit@1:0.013625	 hit@5:0.0396	 hit@10: 0.0656
target: 	 mrr: 0.042473	 ndcg_5: 0.0340	 ndcg_10: 0.0438	 hit@1:0.015325	 hit@5:0.0527	 hit@10: 0.0833
epoch 52: train_loss = 1.154761, source_hit@10 = 0.0656, source_ndcg@10 = 0.0350, target_hit@10 = 0.0833, target_ndcg@10 = 0.0438

2024-07-04 21:23:55.730203: step 9947/68600 (epoch 53/200), loss = 1.150058 (198.824 sec/epoch), lr: 0.000232
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.050838	 ndcg_5: 0.0417	 ndcg_10: 0.0533	 hit@1:0.023131	 hit@5:0.0602	 hit@10: 0.0970
target: 	 mrr: 0.042946	 ndcg_5: 0.0341	 ndcg_10: 0.0444	 hit@1:0.016160	 hit@5:0.0518	 hit@10: 0.0841
epoch 53: train_loss = 1.150058, source_hit@10 = 0.0970, source_ndcg@10 = 0.0533, target_hit@10 = 0.0841, target_ndcg@10 = 0.0444

2024-07-04 21:27:15.497783: step 10290/68600 (epoch 54/200), loss = 1.146213 (198.858 sec/epoch), lr: 0.000232
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.040389	 ndcg_5: 0.0321	 ndcg_10: 0.0405	 hit@1:0.014892	 hit@5:0.0507	 hit@10: 0.0770
target: 	 mrr: 0.041253	 ndcg_5: 0.0320	 ndcg_10: 0.0447	 hit@1:0.013653	 hit@5:0.0504	 hit@10: 0.0903
epoch 54: train_loss = 1.146213, source_hit@10 = 0.0770, source_ndcg@10 = 0.0405, target_hit@10 = 0.0903, target_ndcg@10 = 0.0447

2024-07-04 21:30:35.264542: step 10633/68600 (epoch 55/200), loss = 1.142421 (198.854 sec/epoch), lr: 0.000220
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.043523	 ndcg_5: 0.0344	 ndcg_10: 0.0452	 hit@1:0.016160	 hit@5:0.0529	 hit@10: 0.0868
target: 	 mrr: 0.043328	 ndcg_5: 0.0348	 ndcg_10: 0.0449	 hit@1:0.015882	 hit@5:0.0538	 hit@10: 0.0853
epoch 55: train_loss = 1.142421, source_hit@10 = 0.0868, source_ndcg@10 = 0.0452, target_hit@10 = 0.0853, target_ndcg@10 = 0.0449

2024-07-04 21:33:54.975972: step 10976/68600 (epoch 56/200), loss = 1.140146 (198.798 sec/epoch), lr: 0.000220
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.054995	 ndcg_5: 0.0463	 ndcg_10: 0.0570	 hit@1:0.025032	 hit@5:0.0681	 hit@10: 0.1014
target: 	 mrr: 0.041967	 ndcg_5: 0.0324	 ndcg_10: 0.0441	 hit@1:0.015325	 hit@5:0.0496	 hit@10: 0.0864
epoch 56: train_loss = 1.140146, source_hit@10 = 0.1014, source_ndcg@10 = 0.0570, target_hit@10 = 0.0864, target_ndcg@10 = 0.0441

2024-07-04 21:37:15.199846: step 11319/68600 (epoch 57/200), loss = 1.138102 (199.311 sec/epoch), lr: 0.000220
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.023492	 ndcg_5: 0.0141	 ndcg_10: 0.0218	 hit@1:0.004436	 hit@5:0.0244	 hit@10: 0.0485
target: 	 mrr: 0.044699	 ndcg_5: 0.0358	 ndcg_10: 0.0471	 hit@1:0.016718	 hit@5:0.0549	 hit@10: 0.0903
epoch 57: train_loss = 1.138102, source_hit@10 = 0.0485, source_ndcg@10 = 0.0218, target_hit@10 = 0.0903, target_ndcg@10 = 0.0471

2024-07-04 21:40:34.901446: step 11662/68600 (epoch 58/200), loss = 1.133178 (198.788 sec/epoch), lr: 0.000209
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.050021	 ndcg_5: 0.0399	 ndcg_10: 0.0518	 hit@1:0.021863	 hit@5:0.0583	 hit@10: 0.0954
target: 	 mrr: 0.028848	 ndcg_5: 0.0214	 ndcg_10: 0.0292	 hit@1:0.007802	 hit@5:0.0346	 hit@10: 0.0585
epoch 58: train_loss = 1.133178, source_hit@10 = 0.0954, source_ndcg@10 = 0.0518, target_hit@10 = 0.0585, target_ndcg@10 = 0.0292

2024-07-04 21:43:54.615644: step 12005/68600 (epoch 59/200), loss = 1.132691 (198.789 sec/epoch), lr: 0.000209
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.044605	 ndcg_5: 0.0365	 ndcg_10: 0.0452	 hit@1:0.018061	 hit@5:0.0551	 hit@10: 0.0824
target: 	 mrr: 0.039293	 ndcg_5: 0.0310	 ndcg_10: 0.0402	 hit@1:0.013653	 hit@5:0.0476	 hit@10: 0.0766
epoch 59: train_loss = 1.132691, source_hit@10 = 0.0824, source_ndcg@10 = 0.0452, target_hit@10 = 0.0766, target_ndcg@10 = 0.0402

2024-07-04 21:47:14.435426: step 12348/68600 (epoch 60/200), loss = 1.128026 (198.909 sec/epoch), lr: 0.000209
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.042717	 ndcg_5: 0.0330	 ndcg_10: 0.0425	 hit@1:0.016793	 hit@5:0.0488	 hit@10: 0.0786
target: 	 mrr: 0.042527	 ndcg_5: 0.0340	 ndcg_10: 0.0443	 hit@1:0.016160	 hit@5:0.0513	 hit@10: 0.0839
epoch 60: train_loss = 1.128026, source_hit@10 = 0.0786, source_ndcg@10 = 0.0425, target_hit@10 = 0.0839, target_ndcg@10 = 0.0443

2024-07-04 21:50:34.142736: step 12691/68600 (epoch 61/200), loss = 1.126284 (198.796 sec/epoch), lr: 0.000209
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.044327	 ndcg_5: 0.0348	 ndcg_10: 0.0464	 hit@1:0.017110	 hit@5:0.0529	 hit@10: 0.0894
target: 	 mrr: 0.043494	 ndcg_5: 0.0363	 ndcg_10: 0.0458	 hit@1:0.016718	 hit@5:0.0566	 hit@10: 0.0867
epoch 61: train_loss = 1.126284, source_hit@10 = 0.0894, source_ndcg@10 = 0.0464, target_hit@10 = 0.0867, target_ndcg@10 = 0.0458

2024-07-04 21:53:53.943780: step 13034/68600 (epoch 62/200), loss = 1.124908 (198.888 sec/epoch), lr: 0.000209
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.053520	 ndcg_5: 0.0454	 ndcg_10: 0.0557	 hit@1:0.023447	 hit@5:0.0665	 hit@10: 0.0985
target: 	 mrr: 0.043270	 ndcg_5: 0.0350	 ndcg_10: 0.0448	 hit@1:0.015882	 hit@5:0.0538	 hit@10: 0.0844
epoch 62: train_loss = 1.124908, source_hit@10 = 0.0985, source_ndcg@10 = 0.0557, target_hit@10 = 0.0844, target_ndcg@10 = 0.0448

2024-07-04 21:57:13.706612: step 13377/68600 (epoch 63/200), loss = 1.122296 (198.856 sec/epoch), lr: 0.000209
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.047307	 ndcg_5: 0.0392	 ndcg_10: 0.0490	 hit@1:0.019011	 hit@5:0.0596	 hit@10: 0.0897
target: 	 mrr: 0.043259	 ndcg_5: 0.0347	 ndcg_10: 0.0449	 hit@1:0.016718	 hit@5:0.0527	 hit@10: 0.0841
epoch 63: train_loss = 1.122296, source_hit@10 = 0.0897, source_ndcg@10 = 0.0490, target_hit@10 = 0.0841, target_ndcg@10 = 0.0449

2024-07-04 22:00:33.578591: step 13720/68600 (epoch 64/200), loss = 1.118576 (198.960 sec/epoch), lr: 0.000199
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.045337	 ndcg_5: 0.0364	 ndcg_10: 0.0475	 hit@1:0.017110	 hit@5:0.0554	 hit@10: 0.0897
target: 	 mrr: 0.045476	 ndcg_5: 0.0373	 ndcg_10: 0.0478	 hit@1:0.018668	 hit@5:0.0560	 hit@10: 0.0892
epoch 64: train_loss = 1.118576, source_hit@10 = 0.0897, source_ndcg@10 = 0.0475, target_hit@10 = 0.0892, target_ndcg@10 = 0.0478

2024-07-04 22:03:53.290277: step 14063/68600 (epoch 65/200), loss = 1.116057 (198.797 sec/epoch), lr: 0.000199
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.046947	 ndcg_5: 0.0391	 ndcg_10: 0.0483	 hit@1:0.018695	 hit@5:0.0593	 hit@10: 0.0881
target: 	 mrr: 0.041328	 ndcg_5: 0.0322	 ndcg_10: 0.0433	 hit@1:0.015603	 hit@5:0.0488	 hit@10: 0.0833
epoch 65: train_loss = 1.116057, source_hit@10 = 0.0881, source_ndcg@10 = 0.0483, target_hit@10 = 0.0833, target_ndcg@10 = 0.0433

2024-07-04 22:07:13.056920: step 14406/68600 (epoch 66/200), loss = 1.111881 (198.853 sec/epoch), lr: 0.000189
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.042095	 ndcg_5: 0.0346	 ndcg_10: 0.0426	 hit@1:0.013942	 hit@5:0.0554	 hit@10: 0.0805
target: 	 mrr: 0.040549	 ndcg_5: 0.0319	 ndcg_10: 0.0430	 hit@1:0.013931	 hit@5:0.0504	 hit@10: 0.0850
epoch 66: train_loss = 1.111881, source_hit@10 = 0.0805, source_ndcg@10 = 0.0426, target_hit@10 = 0.0850, target_ndcg@10 = 0.0430

2024-07-04 22:10:32.762592: step 14749/68600 (epoch 67/200), loss = 1.106779 (198.794 sec/epoch), lr: 0.000179
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.044140	 ndcg_5: 0.0350	 ndcg_10: 0.0455	 hit@1:0.016160	 hit@5:0.0542	 hit@10: 0.0868
target: 	 mrr: 0.045573	 ndcg_5: 0.0371	 ndcg_10: 0.0478	 hit@1:0.018111	 hit@5:0.0554	 hit@10: 0.0892
epoch 67: train_loss = 1.106779, source_hit@10 = 0.0868, source_ndcg@10 = 0.0455, target_hit@10 = 0.0892, target_ndcg@10 = 0.0478

2024-07-04 22:13:52.540044: step 15092/68600 (epoch 68/200), loss = 1.103378 (198.872 sec/epoch), lr: 0.000179
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.047616	 ndcg_5: 0.0387	 ndcg_10: 0.0500	 hit@1:0.018061	 hit@5:0.0586	 hit@10: 0.0938
target: 	 mrr: 0.040948	 ndcg_5: 0.0314	 ndcg_10: 0.0431	 hit@1:0.015882	 hit@5:0.0474	 hit@10: 0.0839
epoch 68: train_loss = 1.103378, source_hit@10 = 0.0938, source_ndcg@10 = 0.0500, target_hit@10 = 0.0839, target_ndcg@10 = 0.0431

2024-07-04 22:17:12.312468: step 15435/68600 (epoch 69/200), loss = 1.099968 (198.865 sec/epoch), lr: 0.000170
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.048028	 ndcg_5: 0.0394	 ndcg_10: 0.0503	 hit@1:0.019962	 hit@5:0.0593	 hit@10: 0.0935
target: 	 mrr: 0.041697	 ndcg_5: 0.0334	 ndcg_10: 0.0447	 hit@1:0.014489	 hit@5:0.0532	 hit@10: 0.0886
epoch 69: train_loss = 1.099968, source_hit@10 = 0.0935, source_ndcg@10 = 0.0503, target_hit@10 = 0.0886, target_ndcg@10 = 0.0447

2024-07-04 22:20:32.098222: step 15778/68600 (epoch 70/200), loss = 1.095991 (198.872 sec/epoch), lr: 0.000170
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.049854	 ndcg_5: 0.0424	 ndcg_10: 0.0519	 hit@1:0.020596	 hit@5:0.0643	 hit@10: 0.0938
target: 	 mrr: 0.041998	 ndcg_5: 0.0333	 ndcg_10: 0.0440	 hit@1:0.015882	 hit@5:0.0510	 hit@10: 0.0844
epoch 70: train_loss = 1.095991, source_hit@10 = 0.0938, source_ndcg@10 = 0.0519, target_hit@10 = 0.0844, target_ndcg@10 = 0.0440

2024-07-04 22:23:51.843340: step 16121/68600 (epoch 71/200), loss = 1.092460 (198.832 sec/epoch), lr: 0.000170
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.042907	 ndcg_5: 0.0346	 ndcg_10: 0.0438	 hit@1:0.016160	 hit@5:0.0526	 hit@10: 0.0811
target: 	 mrr: 0.039631	 ndcg_5: 0.0312	 ndcg_10: 0.0409	 hit@1:0.013653	 hit@5:0.0488	 hit@10: 0.0786
epoch 71: train_loss = 1.092460, source_hit@10 = 0.0811, source_ndcg@10 = 0.0438, target_hit@10 = 0.0786, target_ndcg@10 = 0.0409

2024-07-04 22:27:11.669370: step 16464/68600 (epoch 72/200), loss = 1.091004 (198.916 sec/epoch), lr: 0.000162
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.047273	 ndcg_5: 0.0372	 ndcg_10: 0.0492	 hit@1:0.018061	 hit@5:0.0545	 hit@10: 0.0919
target: 	 mrr: 0.040392	 ndcg_5: 0.0320	 ndcg_10: 0.0419	 hit@1:0.015603	 hit@5:0.0488	 hit@10: 0.0802
epoch 72: train_loss = 1.091004, source_hit@10 = 0.0919, source_ndcg@10 = 0.0492, target_hit@10 = 0.0802, target_ndcg@10 = 0.0419

2024-07-04 22:30:31.500358: step 16807/68600 (epoch 73/200), loss = 1.088636 (198.918 sec/epoch), lr: 0.000162
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.044085	 ndcg_5: 0.0358	 ndcg_10: 0.0459	 hit@1:0.016793	 hit@5:0.0558	 hit@10: 0.0871
target: 	 mrr: 0.035186	 ndcg_5: 0.0269	 ndcg_10: 0.0365	 hit@1:0.010031	 hit@5:0.0432	 hit@10: 0.0733
epoch 73: train_loss = 1.088636, source_hit@10 = 0.0871, source_ndcg@10 = 0.0459, target_hit@10 = 0.0733, target_ndcg@10 = 0.0365

2024-07-04 22:33:51.285153: step 17150/68600 (epoch 74/200), loss = 1.085535 (198.871 sec/epoch), lr: 0.000154
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.048551	 ndcg_5: 0.0407	 ndcg_10: 0.0503	 hit@1:0.018695	 hit@5:0.0615	 hit@10: 0.0913
target: 	 mrr: 0.039869	 ndcg_5: 0.0317	 ndcg_10: 0.0426	 hit@1:0.012260	 hit@5:0.0513	 hit@10: 0.0855
epoch 74: train_loss = 1.085535, source_hit@10 = 0.0913, source_ndcg@10 = 0.0503, target_hit@10 = 0.0855, target_ndcg@10 = 0.0426

2024-07-04 22:37:11.094693: step 17493/68600 (epoch 75/200), loss = 1.082712 (198.900 sec/epoch), lr: 0.000154
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.044332	 ndcg_5: 0.0365	 ndcg_10: 0.0476	 hit@1:0.014892	 hit@5:0.0586	 hit@10: 0.0932
target: 	 mrr: 0.038728	 ndcg_5: 0.0299	 ndcg_10: 0.0403	 hit@1:0.011981	 hit@5:0.0476	 hit@10: 0.0800
epoch 75: train_loss = 1.082712, source_hit@10 = 0.0932, source_ndcg@10 = 0.0476, target_hit@10 = 0.0800, target_ndcg@10 = 0.0403

2024-07-04 22:40:31.159033: step 17836/68600 (epoch 76/200), loss = 1.077405 (199.136 sec/epoch), lr: 0.000146
Evaluating on dev set...
..................................................................
source: 	 mrr: 0.046818	 ndcg_5: 0.0383	 ndcg_10: 0.0496	 hit@1:0.017110	 hit@5:0.0589	 hit@10: 0.0938
target: 	 mrr: 0.042440	 ndcg_5: 0.0339	 ndcg_10: 0.0443	 hit@1:0.014767	 hit@5:0.0529	 hit@10: 0.0855
epoch 76: train_loss = 1.077405, source_hit@10 = 0.0938, source_ndcg@10 = 0.0496, target_hit@10 = 0.0855, target_ndcg@10 = 0.0443
early termination of training
