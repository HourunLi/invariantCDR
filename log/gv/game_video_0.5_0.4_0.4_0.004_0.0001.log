nohup: ignoring input
using gpu:0 to train the model
using gpu:0 to train the model
cuda:0
Namespace(A_split=False, JK='sum', a_fold=100, aggregate=False, alpha=0.5, batch_size=1024, beta_inter=0.4, conv_layers=4, cuda=True, decay_epoch=10, device=device(type='cuda', index=0), device_id='0', domains='game_video', dropout=0.5, epoch=80, feature_dim=126, hidden_dim=126, inter_tau=0.2, intra_tau=1, lambda_critic=0.4, leakey=0.01, load=False, log='logs.txt', log_epoch=1, lr=0.004, lr_decay=0.95, min_epoch=50, mode='train', model_file=None, model_name='gv', momentum=0.98, num_latent_factors=3, num_negative=100, optim='adam', patience=50, proj_layers=1, projection=1, residual=1, save=True, save_dir='./saved_models', seed=32, similarity_tau=0.1, test_sample_number=999, transfer_epoch=50, user_batch_size=256, weight_decay=0.0001)
number_user 25025
number_item 12319
/home/hourun/invariantCDR_v2/invariantCDR/utils/GraphMaker.py:46: RuntimeWarning: divide by zero encountered in power
  r_inv = np.power(rowsum, -1).flatten()
real graph loaded!
number_user 19457
number_item 8751
real graph loaded!
graph loaded!
Loading data from game_video with batch size 1024...
unseen test: 0
test length: 1381
unseen test: 0
test length: 1304
unseen test: 0
test length: 1435
unseen test: 0
test length: 1458
source_user_num 25025
target_user_num 19457
source_item_num 12319
target_item_num 8751
shared users id: 1737
test users 226, 217
unseen test: 0
dev length: 1000
unseen test: 0
dev length: 1000
source train data : 155036, target train data: 156091, source test data : 1304, target test data : 1458, source dev data : 1000, target dev data : 1000
2024-08-02 10:27:59.708271: step 304/24320 (epoch 1/80), loss = 1.302655 (35.422 sec/epoch), lr: 0.004000
Evaluating on dev set...
...........................
source: 	 mrr: 0.029867	 ndcg_5: 0.0184	 ndcg_10: 0.0278	 hit@1:0.007965	 hit@5:0.0290	 hit@10: 0.0587
target: 	 mrr: 0.025538	 ndcg_5: 0.0184	 ndcg_10: 0.0247	 hit@1:0.006272	 hit@5:0.0314	 hit@10: 0.0516
source best!
.............
source: 	 mrr: 0.028738	 ndcg_5: 0.0153	 ndcg_10: 0.0274	 hit@1:0.005368	 hit@5:0.0261	 hit@10: 0.0644
target best!
..............target: 	 mrr: 0.024945	 ndcg_5: 0.0170	 ndcg_10: 0.0250	 hit@1:0.005487	 hit@5:0.0288	 hit@10: 0.0535
epoch 1: train_loss = 1.302655, source_hit@10 = 0.0644, source_ndcg@10 = 0.0274, target_hit@10 = 0.0535, target_ndcg@10 = 0.0250

2024-08-02 10:28:37.110160: step 608/24320 (epoch 2/80), loss = 1.115340 (36.859 sec/epoch), lr: 0.004000
Evaluating on dev set...
...........................
source: 	 mrr: 0.034582	 ndcg_5: 0.0258	 ndcg_10: 0.0328	 hit@1:0.013034	 hit@5:0.0391	 hit@10: 0.0608
target: 	 mrr: 0.030441	 ndcg_5: 0.0246	 ndcg_10: 0.0285	 hit@1:0.012544	 hit@5:0.0390	 hit@10: 0.0516
source best!
.............
source: 	 mrr: 0.036597	 ndcg_5: 0.0268	 ndcg_10: 0.0384	 hit@1:0.010736	 hit@5:0.0445	 hit@10: 0.0805
target best!
..............target: 	 mrr: 0.028991	 ndcg_5: 0.0212	 ndcg_10: 0.0289	 hit@1:0.008916	 hit@5:0.0329	 hit@10: 0.0569
epoch 2: train_loss = 1.115340, source_hit@10 = 0.0805, source_ndcg@10 = 0.0384, target_hit@10 = 0.0569, target_ndcg@10 = 0.0289
new best model saved.

2024-08-02 10:29:13.785541: step 912/24320 (epoch 3/80), loss = 1.089289 (36.034 sec/epoch), lr: 0.004000
Evaluating on dev set...
...........................
source: 	 mrr: 0.036623	 ndcg_5: 0.0246	 ndcg_10: 0.0363	 hit@1:0.009413	 hit@5:0.0398	 hit@10: 0.0768
target: 	 mrr: 0.036652	 ndcg_5: 0.0272	 ndcg_10: 0.0363	 hit@1:0.012544	 hit@5:0.0418	 hit@10: 0.0704
source best!
.............
source: 	 mrr: 0.036575	 ndcg_5: 0.0257	 ndcg_10: 0.0378	 hit@1:0.009202	 hit@5:0.0429	 hit@10: 0.0813
target best!
..............target: 	 mrr: 0.035055	 ndcg_5: 0.0255	 ndcg_10: 0.0332	 hit@1:0.010288	 hit@5:0.0398	 hit@10: 0.0638
epoch 3: train_loss = 1.089289, source_hit@10 = 0.0813, source_ndcg@10 = 0.0378, target_hit@10 = 0.0638, target_ndcg@10 = 0.0332
new best model saved.

2024-08-02 10:29:51.571989: step 1216/24320 (epoch 4/80), loss = 1.074900 (37.153 sec/epoch), lr: 0.004000
Evaluating on dev set...
...........................
source: 	 mrr: 0.041817	 ndcg_5: 0.0320	 ndcg_10: 0.0417	 hit@1:0.012310	 hit@5:0.0529	 hit@10: 0.0825
target: 	 mrr: 0.047659	 ndcg_5: 0.0367	 ndcg_10: 0.0517	 hit@1:0.016028	 hit@5:0.0585	 hit@10: 0.1045
source best!
.............
source: 	 mrr: 0.038086	 ndcg_5: 0.0257	 ndcg_10: 0.0408	 hit@1:0.006902	 hit@5:0.0445	 hit@10: 0.0913
target best!
..............target: 	 mrr: 0.050742	 ndcg_5: 0.0411	 ndcg_10: 0.0546	 hit@1:0.017833	 hit@5:0.0638	 hit@10: 0.1063
epoch 4: train_loss = 1.074900, source_hit@10 = 0.0913, source_ndcg@10 = 0.0408, target_hit@10 = 0.1063, target_ndcg@10 = 0.0546
new best model saved.

2024-08-02 10:30:28.976346: step 1520/24320 (epoch 5/80), loss = 1.062395 (36.770 sec/epoch), lr: 0.004000
Evaluating on dev set...
...........................
source: 	 mrr: 0.030363	 ndcg_5: 0.0205	 ndcg_10: 0.0309	 hit@1:0.007241	 hit@5:0.0340	 hit@10: 0.0659
target: 	 mrr: 0.051909	 ndcg_5: 0.0441	 ndcg_10: 0.0557	 hit@1:0.018815	 hit@5:0.0697	 hit@10: 0.1059
target best!
..............target: 	 mrr: 0.054230	 ndcg_5: 0.0438	 ndcg_10: 0.0566	 hit@1:0.021262	 hit@5:0.0652	 hit@10: 0.1049
epoch 5: train_loss = 1.062395, source_hit@10 = 0.0659, source_ndcg@10 = 0.0309, target_hit@10 = 0.1049, target_ndcg@10 = 0.0566

2024-08-02 10:31:05.895216: step 1824/24320 (epoch 6/80), loss = 1.052081 (36.504 sec/epoch), lr: 0.004000
Evaluating on dev set...
...........................
source: 	 mrr: 0.038059	 ndcg_5: 0.0271	 ndcg_10: 0.0389	 hit@1:0.007965	 hit@5:0.0463	 hit@10: 0.0833
target: 	 mrr: 0.036333	 ndcg_5: 0.0251	 ndcg_10: 0.0367	 hit@1:0.011847	 hit@5:0.0397	 hit@10: 0.0767
epoch 6: train_loss = 1.052081, source_hit@10 = 0.0833, source_ndcg@10 = 0.0389, target_hit@10 = 0.0767, target_ndcg@10 = 0.0367

2024-08-02 10:31:42.654368: step 2128/24320 (epoch 7/80), loss = 1.046843 (36.462 sec/epoch), lr: 0.004000
Evaluating on dev set...
...........................
source: 	 mrr: 0.016965	 ndcg_5: 0.0099	 ndcg_10: 0.0157	 hit@1:0.003621	 hit@5:0.0159	 hit@10: 0.0340
target: 	 mrr: 0.046902	 ndcg_5: 0.0386	 ndcg_10: 0.0522	 hit@1:0.014634	 hit@5:0.0634	 hit@10: 0.1052
epoch 7: train_loss = 1.046843, source_hit@10 = 0.0340, source_ndcg@10 = 0.0157, target_hit@10 = 0.1052, target_ndcg@10 = 0.0522

2024-08-02 10:32:19.789182: step 2432/24320 (epoch 8/80), loss = 1.042318 (36.839 sec/epoch), lr: 0.004000
Evaluating on dev set...
...........................
source: 	 mrr: 0.030456	 ndcg_5: 0.0201	 ndcg_10: 0.0301	 hit@1:0.004345	 hit@5:0.0362	 hit@10: 0.0673
target: 	 mrr: 0.054911	 ndcg_5: 0.0479	 ndcg_10: 0.0606	 hit@1:0.019512	 hit@5:0.0767	 hit@10: 0.1164
target best!
..............target: 	 mrr: 0.052855	 ndcg_5: 0.0431	 ndcg_10: 0.0605	 hit@1:0.016461	 hit@5:0.0700	 hit@10: 0.1235
epoch 8: train_loss = 1.042318, source_hit@10 = 0.0673, source_ndcg@10 = 0.0301, target_hit@10 = 0.1235, target_ndcg@10 = 0.0605

2024-08-02 10:32:56.722723: step 2736/24320 (epoch 9/80), loss = 1.036351 (36.513 sec/epoch), lr: 0.004000
Evaluating on dev set...
...........................
source: 	 mrr: 0.037107	 ndcg_5: 0.0266	 ndcg_10: 0.0375	 hit@1:0.008689	 hit@5:0.0456	 hit@10: 0.0797
target: 	 mrr: 0.042272	 ndcg_5: 0.0320	 ndcg_10: 0.0437	 hit@1:0.011847	 hit@5:0.0537	 hit@10: 0.0899
epoch 9: train_loss = 1.036351, source_hit@10 = 0.0797, source_ndcg@10 = 0.0375, target_hit@10 = 0.0899, target_ndcg@10 = 0.0437

2024-08-02 10:33:33.663202: step 3040/24320 (epoch 10/80), loss = 1.031245 (36.633 sec/epoch), lr: 0.004000
Evaluating on dev set...
...........................
source: 	 mrr: 0.037683	 ndcg_5: 0.0261	 ndcg_10: 0.0373	 hit@1:0.008689	 hit@5:0.0442	 hit@10: 0.0789
target: 	 mrr: 0.038192	 ndcg_5: 0.0291	 ndcg_10: 0.0410	 hit@1:0.009059	 hit@5:0.0495	 hit@10: 0.0864
epoch 10: train_loss = 1.031245, source_hit@10 = 0.0789, source_ndcg@10 = 0.0373, target_hit@10 = 0.0864, target_ndcg@10 = 0.0410

2024-08-02 10:34:10.886505: step 3344/24320 (epoch 11/80), loss = 1.030092 (36.928 sec/epoch), lr: 0.004000
Evaluating on dev set...
...........................
source: 	 mrr: 0.033536	 ndcg_5: 0.0220	 ndcg_10: 0.0311	 hit@1:0.009413	 hit@5:0.0340	 hit@10: 0.0623
target: 	 mrr: 0.048838	 ndcg_5: 0.0394	 ndcg_10: 0.0523	 hit@1:0.014634	 hit@5:0.0634	 hit@10: 0.1038
epoch 11: train_loss = 1.030092, source_hit@10 = 0.0623, source_ndcg@10 = 0.0311, target_hit@10 = 0.1038, target_ndcg@10 = 0.0523

2024-08-02 10:34:48.342221: step 3648/24320 (epoch 12/80), loss = 1.026262 (37.158 sec/epoch), lr: 0.004000
Evaluating on dev set...
...........................
source: 	 mrr: 0.032141	 ndcg_5: 0.0225	 ndcg_10: 0.0315	 hit@1:0.004345	 hit@5:0.0406	 hit@10: 0.0688
target: 	 mrr: 0.046149	 ndcg_5: 0.0374	 ndcg_10: 0.0476	 hit@1:0.018815	 hit@5:0.0557	 hit@10: 0.0878
epoch 12: train_loss = 1.026262, source_hit@10 = 0.0688, source_ndcg@10 = 0.0315, target_hit@10 = 0.0878, target_ndcg@10 = 0.0476

2024-08-02 10:35:25.644712: step 3952/24320 (epoch 13/80), loss = 1.022703 (37.007 sec/epoch), lr: 0.003800
Evaluating on dev set...
...........................
source: 	 mrr: 0.029351	 ndcg_5: 0.0183	 ndcg_10: 0.0286	 hit@1:0.006517	 hit@5:0.0304	 hit@10: 0.0630
target: 	 mrr: 0.049852	 ndcg_5: 0.0431	 ndcg_10: 0.0526	 hit@1:0.016725	 hit@5:0.0704	 hit@10: 0.1003
epoch 13: train_loss = 1.022703, source_hit@10 = 0.0630, source_ndcg@10 = 0.0286, target_hit@10 = 0.1003, target_ndcg@10 = 0.0526

2024-08-02 10:36:02.423056: step 4256/24320 (epoch 14/80), loss = 1.020922 (36.468 sec/epoch), lr: 0.003800
Evaluating on dev set...
...........................
source: 	 mrr: 0.038813	 ndcg_5: 0.0275	 ndcg_10: 0.0390	 hit@1:0.009413	 hit@5:0.0471	 hit@10: 0.0833
target: 	 mrr: 0.046480	 ndcg_5: 0.0375	 ndcg_10: 0.0505	 hit@1:0.014634	 hit@5:0.0592	 hit@10: 0.0990
epoch 14: train_loss = 1.020922, source_hit@10 = 0.0833, source_ndcg@10 = 0.0390, target_hit@10 = 0.0990, target_ndcg@10 = 0.0505

2024-08-02 10:36:39.726990: step 4560/24320 (epoch 15/80), loss = 1.019559 (37.004 sec/epoch), lr: 0.003800
Evaluating on dev set...
...........................
source: 	 mrr: 0.035221	 ndcg_5: 0.0271	 ndcg_10: 0.0357	 hit@1:0.009413	 hit@5:0.0442	 hit@10: 0.0710
target: 	 mrr: 0.051371	 ndcg_5: 0.0456	 ndcg_10: 0.0556	 hit@1:0.019512	 hit@5:0.0718	 hit@10: 0.1031
epoch 15: train_loss = 1.019559, source_hit@10 = 0.0710, source_ndcg@10 = 0.0357, target_hit@10 = 0.1031, target_ndcg@10 = 0.0556

2024-08-02 10:37:16.153943: step 4864/24320 (epoch 16/80), loss = 1.017402 (36.128 sec/epoch), lr: 0.003800
Evaluating on dev set...
...........................
source: 	 mrr: 0.031663	 ndcg_5: 0.0199	 ndcg_10: 0.0299	 hit@1:0.005793	 hit@5:0.0340	 hit@10: 0.0652
target: 	 mrr: 0.047732	 ndcg_5: 0.0367	 ndcg_10: 0.0541	 hit@1:0.017422	 hit@5:0.0592	 hit@10: 0.1136
epoch 16: train_loss = 1.017402, source_hit@10 = 0.0652, source_ndcg@10 = 0.0299, target_hit@10 = 0.1136, target_ndcg@10 = 0.0541

2024-08-02 10:37:53.025185: step 5168/24320 (epoch 17/80), loss = 1.013695 (36.578 sec/epoch), lr: 0.003610
Evaluating on dev set...
...........................
source: 	 mrr: 0.031194	 ndcg_5: 0.0217	 ndcg_10: 0.0300	 hit@1:0.006517	 hit@5:0.0362	 hit@10: 0.0623
target: 	 mrr: 0.041668	 ndcg_5: 0.0349	 ndcg_10: 0.0427	 hit@1:0.011150	 hit@5:0.0578	 hit@10: 0.0822
epoch 17: train_loss = 1.013695, source_hit@10 = 0.0623, source_ndcg@10 = 0.0300, target_hit@10 = 0.0822, target_ndcg@10 = 0.0427

2024-08-02 10:38:30.400026: step 5472/24320 (epoch 18/80), loss = 1.010027 (37.075 sec/epoch), lr: 0.003429
Evaluating on dev set...
...........................
source: 	 mrr: 0.033808	 ndcg_5: 0.0217	 ndcg_10: 0.0328	 hit@1:0.008689	 hit@5:0.0355	 hit@10: 0.0702
target: 	 mrr: 0.037918	 ndcg_5: 0.0292	 ndcg_10: 0.0384	 hit@1:0.011150	 hit@5:0.0474	 hit@10: 0.0767
epoch 18: train_loss = 1.010027, source_hit@10 = 0.0702, source_ndcg@10 = 0.0328, target_hit@10 = 0.0767, target_ndcg@10 = 0.0384

2024-08-02 10:39:07.328972: step 5776/24320 (epoch 19/80), loss = 1.005065 (36.636 sec/epoch), lr: 0.003258
Evaluating on dev set...
...........................
source: 	 mrr: 0.034848	 ndcg_5: 0.0245	 ndcg_10: 0.0307	 hit@1:0.011586	 hit@5:0.0377	 hit@10: 0.0572
target: 	 mrr: 0.055860	 ndcg_5: 0.0495	 ndcg_10: 0.0617	 hit@1:0.022300	 hit@5:0.0753	 hit@10: 0.1136
target best!
..............target: 	 mrr: 0.052945	 ndcg_5: 0.0444	 ndcg_10: 0.0603	 hit@1:0.016461	 hit@5:0.0720	 hit@10: 0.1221
epoch 19: train_loss = 1.005065, source_hit@10 = 0.0572, source_ndcg@10 = 0.0307, target_hit@10 = 0.1221, target_ndcg@10 = 0.0603

2024-08-02 10:39:44.110104: step 6080/24320 (epoch 20/80), loss = 1.005872 (36.350 sec/epoch), lr: 0.003258
Evaluating on dev set...
...........................
source: 	 mrr: 0.039511	 ndcg_5: 0.0294	 ndcg_10: 0.0401	 hit@1:0.009413	 hit@5:0.0492	 hit@10: 0.0825
target: 	 mrr: 0.039888	 ndcg_5: 0.0303	 ndcg_10: 0.0400	 hit@1:0.014634	 hit@5:0.0467	 hit@10: 0.0767
epoch 20: train_loss = 1.005872, source_hit@10 = 0.0825, source_ndcg@10 = 0.0401, target_hit@10 = 0.0767, target_ndcg@10 = 0.0400

2024-08-02 10:40:21.379319: step 6384/24320 (epoch 21/80), loss = 1.000490 (36.970 sec/epoch), lr: 0.003095
Evaluating on dev set...
...........................
source: 	 mrr: 0.036734	 ndcg_5: 0.0253	 ndcg_10: 0.0364	 hit@1:0.007965	 hit@5:0.0427	 hit@10: 0.0775
target: 	 mrr: 0.049445	 ndcg_5: 0.0391	 ndcg_10: 0.0533	 hit@1:0.016725	 hit@5:0.0627	 hit@10: 0.1059
epoch 21: train_loss = 1.000490, source_hit@10 = 0.0775, source_ndcg@10 = 0.0364, target_hit@10 = 0.1059, target_ndcg@10 = 0.0533

2024-08-02 10:40:58.087955: step 6688/24320 (epoch 22/80), loss = 1.000085 (36.413 sec/epoch), lr: 0.003095
Evaluating on dev set...
...........................
source: 	 mrr: 0.038152	 ndcg_5: 0.0269	 ndcg_10: 0.0382	 hit@1:0.010862	 hit@5:0.0442	 hit@10: 0.0797
target: 	 mrr: 0.049678	 ndcg_5: 0.0412	 ndcg_10: 0.0537	 hit@1:0.020906	 hit@5:0.0641	 hit@10: 0.1038
epoch 22: train_loss = 1.000085, source_hit@10 = 0.0797, source_ndcg@10 = 0.0382, target_hit@10 = 0.1038, target_ndcg@10 = 0.0537

2024-08-02 10:41:35.061768: step 6992/24320 (epoch 23/80), loss = 0.998608 (36.679 sec/epoch), lr: 0.003095
Evaluating on dev set...
...........................
source: 	 mrr: 0.034965	 ndcg_5: 0.0229	 ndcg_10: 0.0343	 hit@1:0.007241	 hit@5:0.0398	 hit@10: 0.0753
target: 	 mrr: 0.053432	 ndcg_5: 0.0462	 ndcg_10: 0.0608	 hit@1:0.016028	 hit@5:0.0746	 hit@10: 0.1206
epoch 23: train_loss = 0.998608, source_hit@10 = 0.0753, source_ndcg@10 = 0.0343, target_hit@10 = 0.1206, target_ndcg@10 = 0.0608

2024-08-02 10:42:11.771281: step 7296/24320 (epoch 24/80), loss = 0.996401 (36.400 sec/epoch), lr: 0.003095
Evaluating on dev set...
...........................
source: 	 mrr: 0.025031	 ndcg_5: 0.0155	 ndcg_10: 0.0225	 hit@1:0.005793	 hit@5:0.0253	 hit@10: 0.0471
target: 	 mrr: 0.051240	 ndcg_5: 0.0428	 ndcg_10: 0.0581	 hit@1:0.016725	 hit@5:0.0690	 hit@10: 0.1171
epoch 24: train_loss = 0.996401, source_hit@10 = 0.0471, source_ndcg@10 = 0.0225, target_hit@10 = 0.1171, target_ndcg@10 = 0.0581

2024-08-02 10:42:48.840609: step 7600/24320 (epoch 25/80), loss = 0.992019 (36.772 sec/epoch), lr: 0.002940
Evaluating on dev set...
...........................
source: 	 mrr: 0.031998	 ndcg_5: 0.0229	 ndcg_10: 0.0317	 hit@1:0.009413	 hit@5:0.0384	 hit@10: 0.0659
target: 	 mrr: 0.050361	 ndcg_5: 0.0430	 ndcg_10: 0.0550	 hit@1:0.017422	 hit@5:0.0704	 hit@10: 0.1080
epoch 25: train_loss = 0.992019, source_hit@10 = 0.0659, source_ndcg@10 = 0.0317, target_hit@10 = 0.1080, target_ndcg@10 = 0.0550

2024-08-02 10:43:25.888251: step 7904/24320 (epoch 26/80), loss = 0.990716 (36.753 sec/epoch), lr: 0.002940
Evaluating on dev set...
...........................
source: 	 mrr: 0.035090	 ndcg_5: 0.0240	 ndcg_10: 0.0320	 hit@1:0.007965	 hit@5:0.0406	 hit@10: 0.0652
target: 	 mrr: 0.054836	 ndcg_5: 0.0441	 ndcg_10: 0.0602	 hit@1:0.020209	 hit@5:0.0676	 hit@10: 0.1171
epoch 26: train_loss = 0.990716, source_hit@10 = 0.0652, source_ndcg@10 = 0.0320, target_hit@10 = 0.1171, target_ndcg@10 = 0.0602

2024-08-02 10:44:02.948515: step 8208/24320 (epoch 27/80), loss = 0.992361 (36.762 sec/epoch), lr: 0.002940
Evaluating on dev set...
...........................
source: 	 mrr: 0.016036	 ndcg_5: 0.0083	 ndcg_10: 0.0138	 hit@1:0.005069	 hit@5:0.0116	 hit@10: 0.0290
target: 	 mrr: 0.041724	 ndcg_5: 0.0327	 ndcg_10: 0.0434	 hit@1:0.012544	 hit@5:0.0544	 hit@10: 0.0878
epoch 27: train_loss = 0.992361, source_hit@10 = 0.0290, source_ndcg@10 = 0.0138, target_hit@10 = 0.0878, target_ndcg@10 = 0.0434

2024-08-02 10:44:40.015961: step 8512/24320 (epoch 28/80), loss = 0.986483 (36.773 sec/epoch), lr: 0.002793
Evaluating on dev set...
...........................
source: 	 mrr: 0.032084	 ndcg_5: 0.0205	 ndcg_10: 0.0300	 hit@1:0.006517	 hit@5:0.0348	 hit@10: 0.0644
target: 	 mrr: 0.063133	 ndcg_5: 0.0560	 ndcg_10: 0.0689	 hit@1:0.025087	 hit@5:0.0857	 hit@10: 0.1261
target best!
..............target: 	 mrr: 0.061942	 ndcg_5: 0.0540	 ndcg_10: 0.0682	 hit@1:0.024691	 hit@5:0.0837	 hit@10: 0.1283
epoch 28: train_loss = 0.986483, source_hit@10 = 0.0644, source_ndcg@10 = 0.0300, target_hit@10 = 0.1283, target_ndcg@10 = 0.0682

2024-08-02 10:45:16.661545: step 8816/24320 (epoch 29/80), loss = 0.987233 (36.221 sec/epoch), lr: 0.002793
Evaluating on dev set...
...........................
source: 	 mrr: 0.038031	 ndcg_5: 0.0263	 ndcg_10: 0.0388	 hit@1:0.008689	 hit@5:0.0442	 hit@10: 0.0833
target: 	 mrr: 0.046260	 ndcg_5: 0.0377	 ndcg_10: 0.0480	 hit@1:0.017422	 hit@5:0.0578	 hit@10: 0.0899
epoch 29: train_loss = 0.987233, source_hit@10 = 0.0833, source_ndcg@10 = 0.0388, target_hit@10 = 0.0899, target_ndcg@10 = 0.0480

2024-08-02 10:45:53.170564: step 9120/24320 (epoch 30/80), loss = 0.985292 (36.214 sec/epoch), lr: 0.002654
Evaluating on dev set...
...........................
source: 	 mrr: 0.033353	 ndcg_5: 0.0212	 ndcg_10: 0.0317	 hit@1:0.007241	 hit@5:0.0355	 hit@10: 0.0688
target: 	 mrr: 0.050572	 ndcg_5: 0.0440	 ndcg_10: 0.0550	 hit@1:0.016028	 hit@5:0.0697	 hit@10: 0.1038
epoch 30: train_loss = 0.985292, source_hit@10 = 0.0688, source_ndcg@10 = 0.0317, target_hit@10 = 0.1038, target_ndcg@10 = 0.0550

2024-08-02 10:46:30.201412: step 9424/24320 (epoch 31/80), loss = 0.982450 (36.734 sec/epoch), lr: 0.002521
Evaluating on dev set...
...........................
source: 	 mrr: 0.041440	 ndcg_5: 0.0291	 ndcg_10: 0.0411	 hit@1:0.013758	 hit@5:0.0434	 hit@10: 0.0811
target: 	 mrr: 0.054713	 ndcg_5: 0.0472	 ndcg_10: 0.0626	 hit@1:0.013937	 hit@5:0.0794	 hit@10: 0.1275
epoch 31: train_loss = 0.982450, source_hit@10 = 0.0811, source_ndcg@10 = 0.0411, target_hit@10 = 0.1275, target_ndcg@10 = 0.0626

2024-08-02 10:47:06.991510: step 9728/24320 (epoch 32/80), loss = 0.982227 (36.495 sec/epoch), lr: 0.002521
Evaluating on dev set...
...........................
source: 	 mrr: 0.033705	 ndcg_5: 0.0241	 ndcg_10: 0.0325	 hit@1:0.012310	 hit@5:0.0362	 hit@10: 0.0623
target: 	 mrr: 0.054557	 ndcg_5: 0.0451	 ndcg_10: 0.0613	 hit@1:0.018815	 hit@5:0.0718	 hit@10: 0.1220
epoch 32: train_loss = 0.982227, source_hit@10 = 0.0623, source_ndcg@10 = 0.0325, target_hit@10 = 0.1220, target_ndcg@10 = 0.0613

2024-08-02 10:47:43.710486: step 10032/24320 (epoch 33/80), loss = 0.979469 (36.421 sec/epoch), lr: 0.002395
Evaluating on dev set...
...........................
source: 	 mrr: 0.035000	 ndcg_5: 0.0263	 ndcg_10: 0.0351	 hit@1:0.010138	 hit@5:0.0434	 hit@10: 0.0710
target: 	 mrr: 0.052170	 ndcg_5: 0.0431	 ndcg_10: 0.0569	 hit@1:0.015331	 hit@5:0.0683	 hit@10: 0.1115
epoch 33: train_loss = 0.979469, source_hit@10 = 0.0710, source_ndcg@10 = 0.0351, target_hit@10 = 0.1115, target_ndcg@10 = 0.0569

2024-08-02 10:48:20.174139: step 10336/24320 (epoch 34/80), loss = 0.975313 (36.148 sec/epoch), lr: 0.002275
Evaluating on dev set...
...........................
source: 	 mrr: 0.034543	 ndcg_5: 0.0238	 ndcg_10: 0.0311	 hit@1:0.012310	 hit@5:0.0348	 hit@10: 0.0579
target: 	 mrr: 0.059603	 ndcg_5: 0.0509	 ndcg_10: 0.0651	 hit@1:0.025087	 hit@5:0.0767	 hit@10: 0.1206
epoch 34: train_loss = 0.975313, source_hit@10 = 0.0579, source_ndcg@10 = 0.0311, target_hit@10 = 0.1206, target_ndcg@10 = 0.0651

2024-08-02 10:48:56.959675: step 10640/24320 (epoch 35/80), loss = 0.973181 (36.490 sec/epoch), lr: 0.002275
Evaluating on dev set...
...........................
source: 	 mrr: 0.034775	 ndcg_5: 0.0232	 ndcg_10: 0.0339	 hit@1:0.010138	 hit@5:0.0362	 hit@10: 0.0702
target: 	 mrr: 0.057621	 ndcg_5: 0.0483	 ndcg_10: 0.0628	 hit@1:0.022300	 hit@5:0.0739	 hit@10: 0.1185
epoch 35: train_loss = 0.973181, source_hit@10 = 0.0702, source_ndcg@10 = 0.0339, target_hit@10 = 0.1185, target_ndcg@10 = 0.0628

2024-08-02 10:49:33.303869: step 10944/24320 (epoch 36/80), loss = 0.972118 (36.050 sec/epoch), lr: 0.002161
Evaluating on dev set...
...........................
source: 	 mrr: 0.035264	 ndcg_5: 0.0247	 ndcg_10: 0.0346	 hit@1:0.007241	 hit@5:0.0427	 hit@10: 0.0731
target: 	 mrr: 0.050810	 ndcg_5: 0.0441	 ndcg_10: 0.0558	 hit@1:0.016028	 hit@5:0.0732	 hit@10: 0.1094
epoch 36: train_loss = 0.972118, source_hit@10 = 0.0731, source_ndcg@10 = 0.0346, target_hit@10 = 0.1094, target_ndcg@10 = 0.0558

2024-08-02 10:50:10.403151: step 11248/24320 (epoch 37/80), loss = 0.969804 (36.794 sec/epoch), lr: 0.002053
Evaluating on dev set...
...........................
source: 	 mrr: 0.042318	 ndcg_5: 0.0325	 ndcg_10: 0.0427	 hit@1:0.015206	 hit@5:0.0507	 hit@10: 0.0825
target: 	 mrr: 0.051572	 ndcg_5: 0.0408	 ndcg_10: 0.0583	 hit@1:0.016028	 hit@5:0.0641	 hit@10: 0.1178
source best!
.............
source: 	 mrr: 0.039853	 ndcg_5: 0.0276	 ndcg_10: 0.0409	 hit@1:0.011503	 hit@5:0.0437	 hit@10: 0.0851
epoch 37: train_loss = 0.969804, source_hit@10 = 0.0851, source_ndcg@10 = 0.0409, target_hit@10 = 0.1178, target_ndcg@10 = 0.0583

2024-08-02 10:50:47.210503: step 11552/24320 (epoch 38/80), loss = 0.967202 (36.400 sec/epoch), lr: 0.002053
Evaluating on dev set...
...........................
source: 	 mrr: 0.034948	 ndcg_5: 0.0251	 ndcg_10: 0.0346	 hit@1:0.010862	 hit@5:0.0398	 hit@10: 0.0695
target: 	 mrr: 0.051158	 ndcg_5: 0.0430	 ndcg_10: 0.0566	 hit@1:0.016725	 hit@5:0.0704	 hit@10: 0.1129
epoch 38: train_loss = 0.967202, source_hit@10 = 0.0695, source_ndcg@10 = 0.0346, target_hit@10 = 0.1129, target_ndcg@10 = 0.0566

2024-08-02 10:51:24.101968: step 11856/24320 (epoch 39/80), loss = 0.965335 (36.593 sec/epoch), lr: 0.001951
Evaluating on dev set...
...........................
source: 	 mrr: 0.028359	 ndcg_5: 0.0178	 ndcg_10: 0.0251	 hit@1:0.005793	 hit@5:0.0304	 hit@10: 0.0529
target: 	 mrr: 0.046490	 ndcg_5: 0.0356	 ndcg_10: 0.0507	 hit@1:0.013937	 hit@5:0.0592	 hit@10: 0.1059
epoch 39: train_loss = 0.965335, source_hit@10 = 0.0529, source_ndcg@10 = 0.0251, target_hit@10 = 0.1059, target_ndcg@10 = 0.0507

2024-08-02 10:52:01.043219: step 12160/24320 (epoch 40/80), loss = 0.965542 (36.636 sec/epoch), lr: 0.001853
Evaluating on dev set...
...........................
source: 	 mrr: 0.039008	 ndcg_5: 0.0291	 ndcg_10: 0.0383	 hit@1:0.013034	 hit@5:0.0449	 hit@10: 0.0739
target: 	 mrr: 0.056947	 ndcg_5: 0.0479	 ndcg_10: 0.0630	 hit@1:0.019512	 hit@5:0.0746	 hit@10: 0.1213
epoch 40: train_loss = 0.965542, source_hit@10 = 0.0739, source_ndcg@10 = 0.0383, target_hit@10 = 0.1213, target_ndcg@10 = 0.0630

2024-08-02 10:52:38.372999: step 12464/24320 (epoch 41/80), loss = 0.962115 (37.034 sec/epoch), lr: 0.001853
Evaluating on dev set...
...........................
source: 	 mrr: 0.024484	 ndcg_5: 0.0143	 ndcg_10: 0.0223	 hit@1:0.005069	 hit@5:0.0239	 hit@10: 0.0492
target: 	 mrr: 0.053092	 ndcg_5: 0.0438	 ndcg_10: 0.0590	 hit@1:0.018815	 hit@5:0.0683	 hit@10: 0.1157
epoch 41: train_loss = 0.962115, source_hit@10 = 0.0492, source_ndcg@10 = 0.0223, target_hit@10 = 0.1157, target_ndcg@10 = 0.0590

2024-08-02 10:53:15.297448: step 12768/24320 (epoch 42/80), loss = 0.961718 (36.628 sec/epoch), lr: 0.001761
Evaluating on dev set...
...........................
source: 	 mrr: 0.037526	 ndcg_5: 0.0304	 ndcg_10: 0.0376	 hit@1:0.013034	 hit@5:0.0500	 hit@10: 0.0731
target: 	 mrr: 0.055124	 ndcg_5: 0.0466	 ndcg_10: 0.0607	 hit@1:0.020209	 hit@5:0.0739	 hit@10: 0.1171
epoch 42: train_loss = 0.961718, source_hit@10 = 0.0731, source_ndcg@10 = 0.0376, target_hit@10 = 0.1171, target_ndcg@10 = 0.0607

2024-08-02 10:53:52.205979: step 13072/24320 (epoch 43/80), loss = 0.960130 (36.610 sec/epoch), lr: 0.001761
Evaluating on dev set...
...........................
source: 	 mrr: 0.033689	 ndcg_5: 0.0248	 ndcg_10: 0.0347	 hit@1:0.010862	 hit@5:0.0391	 hit@10: 0.0702
target: 	 mrr: 0.048408	 ndcg_5: 0.0380	 ndcg_10: 0.0539	 hit@1:0.013240	 hit@5:0.0641	 hit@10: 0.1136
epoch 43: train_loss = 0.960130, source_hit@10 = 0.0702, source_ndcg@10 = 0.0347, target_hit@10 = 0.1136, target_ndcg@10 = 0.0539

2024-08-02 10:54:29.017412: step 13376/24320 (epoch 44/80), loss = 0.957516 (36.502 sec/epoch), lr: 0.001672
Evaluating on dev set...
...........................
source: 	 mrr: 0.034449	 ndcg_5: 0.0249	 ndcg_10: 0.0338	 hit@1:0.009413	 hit@5:0.0398	 hit@10: 0.0681
target: 	 mrr: 0.044828	 ndcg_5: 0.0343	 ndcg_10: 0.0474	 hit@1:0.013240	 hit@5:0.0564	 hit@10: 0.0976
epoch 44: train_loss = 0.957516, source_hit@10 = 0.0681, source_ndcg@10 = 0.0338, target_hit@10 = 0.0976, target_ndcg@10 = 0.0474

2024-08-02 10:55:05.865291: step 13680/24320 (epoch 45/80), loss = 0.954165 (36.553 sec/epoch), lr: 0.001589
Evaluating on dev set...
...........................
source: 	 mrr: 0.033080	 ndcg_5: 0.0223	 ndcg_10: 0.0333	 hit@1:0.006517	 hit@5:0.0398	 hit@10: 0.0739
target: 	 mrr: 0.055593	 ndcg_5: 0.0467	 ndcg_10: 0.0607	 hit@1:0.020906	 hit@5:0.0746	 hit@10: 0.1178
epoch 45: train_loss = 0.954165, source_hit@10 = 0.0739, source_ndcg@10 = 0.0333, target_hit@10 = 0.1178, target_ndcg@10 = 0.0607

2024-08-02 10:55:42.724456: step 13984/24320 (epoch 46/80), loss = 0.954670 (36.539 sec/epoch), lr: 0.001589
Evaluating on dev set...
...........................
source: 	 mrr: 0.036940	 ndcg_5: 0.0264	 ndcg_10: 0.0376	 hit@1:0.012310	 hit@5:0.0413	 hit@10: 0.0768
target: 	 mrr: 0.060880	 ndcg_5: 0.0527	 ndcg_10: 0.0659	 hit@1:0.023693	 hit@5:0.0829	 hit@10: 0.1240
epoch 46: train_loss = 0.954670, source_hit@10 = 0.0768, source_ndcg@10 = 0.0376, target_hit@10 = 0.1240, target_ndcg@10 = 0.0659

2024-08-02 10:56:19.556519: step 14288/24320 (epoch 47/80), loss = 0.955708 (36.538 sec/epoch), lr: 0.001589
Evaluating on dev set...
...........................
source: 	 mrr: 0.033190	 ndcg_5: 0.0230	 ndcg_10: 0.0329	 hit@1:0.007965	 hit@5:0.0391	 hit@10: 0.0695
target: 	 mrr: 0.053599	 ndcg_5: 0.0474	 ndcg_10: 0.0592	 hit@1:0.016725	 hit@5:0.0787	 hit@10: 0.1157
epoch 47: train_loss = 0.955708, source_hit@10 = 0.0695, source_ndcg@10 = 0.0329, target_hit@10 = 0.1157, target_ndcg@10 = 0.0592

2024-08-02 10:56:56.492738: step 14592/24320 (epoch 48/80), loss = 0.952315 (36.625 sec/epoch), lr: 0.001509
Evaluating on dev set...
...........................
source: 	 mrr: 0.041987	 ndcg_5: 0.0298	 ndcg_10: 0.0422	 hit@1:0.016655	 hit@5:0.0434	 hit@10: 0.0818
target: 	 mrr: 0.049165	 ndcg_5: 0.0401	 ndcg_10: 0.0546	 hit@1:0.015331	 hit@5:0.0648	 hit@10: 0.1108
epoch 48: train_loss = 0.952315, source_hit@10 = 0.0818, source_ndcg@10 = 0.0422, target_hit@10 = 0.1108, target_ndcg@10 = 0.0546

2024-08-02 10:57:33.362777: step 14896/24320 (epoch 49/80), loss = 0.949144 (36.564 sec/epoch), lr: 0.001509
Evaluating on dev set...
...........................
source: 	 mrr: 0.034005	 ndcg_5: 0.0232	 ndcg_10: 0.0333	 hit@1:0.007241	 hit@5:0.0398	 hit@10: 0.0710
target: 	 mrr: 0.050425	 ndcg_5: 0.0384	 ndcg_10: 0.0563	 hit@1:0.013937	 hit@5:0.0606	 hit@10: 0.1157
epoch 49: train_loss = 0.949144, source_hit@10 = 0.0710, source_ndcg@10 = 0.0333, target_hit@10 = 0.1157, target_ndcg@10 = 0.0563

2024-08-02 10:58:08.427488: step 15200/24320 (epoch 50/80), loss = 0.948006 (34.771 sec/epoch), lr: 0.001434
Evaluating on dev set...
...........................
source: 	 mrr: 0.039449	 ndcg_5: 0.0283	 ndcg_10: 0.0397	 hit@1:0.010862	 hit@5:0.0456	 hit@10: 0.0811
target: 	 mrr: 0.055793	 ndcg_5: 0.0462	 ndcg_10: 0.0590	 hit@1:0.021603	 hit@5:0.0697	 hit@10: 0.1094
epoch 50: train_loss = 0.948006, source_hit@10 = 0.0811, source_ndcg@10 = 0.0397, target_hit@10 = 0.1094, target_ndcg@10 = 0.0590
shift to transfer learning mode

2024-08-02 10:58:45.543274: step 15504/24320 (epoch 51/80), loss = 0.947045 (36.821 sec/epoch), lr: 0.001434
Evaluating on dev set...
...........................
source: 	 mrr: 0.030414	 ndcg_5: 0.0220	 ndcg_10: 0.0292	 hit@1:0.007965	 hit@5:0.0355	 hit@10: 0.0579
target: 	 mrr: 0.053540	 ndcg_5: 0.0442	 ndcg_10: 0.0594	 hit@1:0.017422	 hit@5:0.0711	 hit@10: 0.1185
epoch 51: train_loss = 0.947045, source_hit@10 = 0.0579, source_ndcg@10 = 0.0292, target_hit@10 = 0.1185, target_ndcg@10 = 0.0594

2024-08-02 10:59:22.712986: step 15808/24320 (epoch 52/80), loss = 0.945521 (36.876 sec/epoch), lr: 0.001362
Evaluating on dev set...
...........................
source: 	 mrr: 0.037170	 ndcg_5: 0.0261	 ndcg_10: 0.0372	 hit@1:0.009413	 hit@5:0.0434	 hit@10: 0.0782
target: 	 mrr: 0.061968	 ndcg_5: 0.0530	 ndcg_10: 0.0691	 hit@1:0.024390	 hit@5:0.0822	 hit@10: 0.1324
epoch 52: train_loss = 0.945521, source_hit@10 = 0.0782, source_ndcg@10 = 0.0372, target_hit@10 = 0.1324, target_ndcg@10 = 0.0691

2024-08-02 11:00:00.562441: step 16112/24320 (epoch 53/80), loss = 0.943845 (37.551 sec/epoch), lr: 0.001362
Evaluating on dev set...
...........................
source: 	 mrr: 0.042227	 ndcg_5: 0.0307	 ndcg_10: 0.0445	 hit@1:0.010862	 hit@5:0.0500	 hit@10: 0.0934
target: 	 mrr: 0.052938	 ndcg_5: 0.0442	 ndcg_10: 0.0575	 hit@1:0.016028	 hit@5:0.0711	 hit@10: 0.1129
epoch 53: train_loss = 0.943845, source_hit@10 = 0.0934, source_ndcg@10 = 0.0445, target_hit@10 = 0.1129, target_ndcg@10 = 0.0575

2024-08-02 11:00:37.958991: step 16416/24320 (epoch 54/80), loss = 0.938240 (37.075 sec/epoch), lr: 0.001294
Evaluating on dev set...
...........................
source: 	 mrr: 0.042309	 ndcg_5: 0.0301	 ndcg_10: 0.0413	 hit@1:0.015206	 hit@5:0.0456	 hit@10: 0.0811
target: 	 mrr: 0.055807	 ndcg_5: 0.0483	 ndcg_10: 0.0619	 hit@1:0.018815	 hit@5:0.0780	 hit@10: 0.1206
epoch 54: train_loss = 0.938240, source_hit@10 = 0.0811, source_ndcg@10 = 0.0413, target_hit@10 = 0.1206, target_ndcg@10 = 0.0619

2024-08-02 11:01:15.872524: step 16720/24320 (epoch 55/80), loss = 0.938030 (37.618 sec/epoch), lr: 0.001294
Evaluating on dev set...
...........................
source: 	 mrr: 0.040961	 ndcg_5: 0.0281	 ndcg_10: 0.0408	 hit@1:0.011586	 hit@5:0.0442	 hit@10: 0.0833
target: 	 mrr: 0.051282	 ndcg_5: 0.0459	 ndcg_10: 0.0549	 hit@1:0.015331	 hit@5:0.0780	 hit@10: 0.1066
epoch 55: train_loss = 0.938030, source_hit@10 = 0.0833, source_ndcg@10 = 0.0408, target_hit@10 = 0.1066, target_ndcg@10 = 0.0549
early termination of training
